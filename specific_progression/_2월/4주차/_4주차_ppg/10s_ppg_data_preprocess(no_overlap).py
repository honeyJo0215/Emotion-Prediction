import os
import numpy as np
from scipy.signal import butter, filtfilt, resample

# ì…ë ¥ ë° ì¶œë ¥ ê²½ë¡œ ì„¤ì •
input_dir = "/home/bcml1/2025_EMOTION/DEAP_npy_files+label/"
label_dir = "/home/bcml1/2025_EMOTION/DEAP_four_labels/"
output_dir = "/home/bcml1/2025_EMOTION/DEAP_PPG_10s_(6,5,1280)/"
os.makedirs(output_dir, exist_ok=True)

# === Butterworth Bandpass í•„í„° (2ì°¨, 0.5Hz ~ 5Hz) ===
def bandpass_filter(data, lowcut=0.5, highcut=5.0, fs=128, order=2):
    nyquist = 0.5 * fs
    low = lowcut / nyquist
    high = highcut / nyquist
    b, a = butter(order, [low, high], btype="band")
    return filtfilt(b, a, data, axis=1)

# === Min-Max ì •ê·œí™” ([-1,1] ë²”ìœ„ë¡œ ë³€í™˜) ===
def min_max_normalization(data):
    min_val = np.min(data, axis=1, keepdims=True)
    max_val = np.max(data, axis=1, keepdims=True)
    return 2 * (data - min_val) / (max_val - min_val) - 1

# === 10ì´ˆ ë‹¨ìœ„ (1280 ìƒ˜í”Œ)ë¡œ Segmentation (overlap ì—†ìŒ) ===
def segment_by_ten_seconds(data, segment_size=1280):
    """
    data: shape (40, num_total_samples)
    Returns shape (num_segments, 40, segment_size)
    where num_segments = num_total_samples // 1280
    """
    num_samples = data.shape[1]
    num_segments = num_samples // segment_size
    # (40, num_segments*1280)ë¡œ ìë¥¸ í›„ num_segmentsì¶•ìœ¼ë¡œ split
    return np.array(np.split(data[:, :num_segments * segment_size], num_segments, axis=1))

# === Multi-Frequency Smoothing (s=2, s=3 ì ìš©) ===
def multi_frequency_smoothing(data, scales=[2, 3]):
    smoothed_signals = []
    for s in scales:
        smoothed = np.apply_along_axis(lambda m: np.convolve(m, np.ones(s)/s, mode='same'), axis=1, arr=data)
        smoothed_signals.append(smoothed)
    return smoothed_signals  # ê° ë°°ì—´ shape: (num_trials, signal_length)

# === Downsamplingì„ ê° segmentì— ì ìš©í•˜ëŠ” í•¨ìˆ˜ ===
def downsample_segment(segment, d, target_length=1280):
    """
    segment: shape (40, 1280) if called after segmentation
    downsample by factor d, then resample back to 1280
    so final shape remains (40, 1280)
    """
    # segment[:, ::d] => reduce to ~1280/d in length
    down = segment[:, ::d]
    # resample back up/down to exactly 1280
    down_resampled = resample(down, target_length, axis=1)
    return down_resampled

# === ê°ì • ë¼ë²¨ ë¶ˆëŸ¬ì˜¤ê¸° ===
def load_emotion_labels(filepath):
    labels = np.load(filepath)  # Shape: (40, 2)  # valence, arousal ê°’
    return labels  # (40, 2)

# === ë°ì´í„° ì²˜ë¦¬ ì‹œì‘ ===
for subject_id in range(1, 23):
    subject_filename = f"s{subject_id:02d}_signals.npy"
    subject_filepath = os.path.join(input_dir, subject_filename)
    label_filepath = os.path.join(label_dir, f"s{subject_id:02d}_emotion_labels.npy")

    if not os.path.exists(subject_filepath) or not os.path.exists(label_filepath):
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {subject_filepath} ë˜ëŠ” {label_filepath}")
        continue

    # 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ
    subject_data = np.load(subject_filepath, allow_pickle=True)  # Shape: (40, 8064)

    # 2ï¸âƒ£ PPG ì‹ í˜¸ (39ë²ˆ ì±„ë„) ì¶”ì¶œ â†’ ì˜ˆìƒ Shape: (40, 8064)
    ppg_data = subject_data[:, 38, :]

    # 3ï¸âƒ£ ì´ˆê¸° 3ì´ˆ(0~2ì´ˆ) ì œê±° â†’ ì˜ˆìƒ Shape: (40, 7680)
    ppg_data = ppg_data[:, 384:]

    # 4ï¸âƒ£ ìƒ˜í”Œ ìˆ˜ê°€ 7680ì´ ì•„ë‹ˆë©´ 7680ìœ¼ë¡œ ë³´ê°„
    if ppg_data.shape[1] != 7680:
        ppg_data = resample(ppg_data, 7680, axis=1)

    # 5ï¸âƒ£ Bandpass Filtering (0.5Hz ~ 5Hz)
    ppg_filtered = bandpass_filter(ppg_data)

    # 6ï¸âƒ£ Min-Max ì •ê·œí™”
    ppg_normalized = min_max_normalization(ppg_filtered)

    # 7ï¸âƒ£ Identity Mapping (ì›ë³¸ ë°ì´í„° ìœ ì§€)
    ppg_identity = ppg_normalized.copy()

    # 8ï¸âƒ£ Multi-Frequency ë³€í™˜ (ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ì—ì„œ smoothing)
    ppg_smooth_s2, ppg_smooth_s3 = multi_frequency_smoothing(ppg_normalized)

    # 9ï¸âƒ£ 1ì´ˆ ë‹¨ìœ„ë¡œ Segmentation ì ìš© (overlap ì—†ìŒ)
    #    => shape: (6, 40, 1280)
    segments_identity = segment_by_ten_seconds(ppg_identity, 1280)
    segments_smooth_s2 = segment_by_ten_seconds(ppg_smooth_s2, 1280)
    segments_smooth_s3 = segment_by_ten_seconds(ppg_smooth_s3, 1280)
    
    # ğŸ”Ÿ Downsampling ì ìš© (d=2, d=3), ê° ê²°ê³¼ shapeë„ (6, 40, 1280)ë¡œ ë§ì¶¤
    segments_downsampled_d2 = np.array([
        downsample_segment(seg, d=2, target_length=1280) for seg in segments_identity
    ])  # shape: (6, 40, 1280)
    segments_downsampled_d3 = np.array([
        downsample_segment(seg, d=3, target_length=1280) for seg in segments_identity
    ])
    
    # 1ï¸âƒ£1ï¸âƒ£ ê°ì • ë¼ë²¨ ë¶ˆëŸ¬ì˜¤ê¸° (Shape: (40, 2))
    labels = load_emotion_labels(label_filepath)

    # 1ï¸âƒ£2ï¸âƒ£ Trial ë³„ë¡œ ìµœì¢… ë°ì´í„°ë¥¼ ìƒì„± ë° ì €ì¥
    #     ê° trialë§ˆë‹¤ shapeëŠ” (6, 5, 1280)ì´ ë¨
    for trial_idx in range(40):
        trial_identity       = segments_identity[:, trial_idx, :]        # (6, 1280)
        trial_smooth_s2      = segments_smooth_s2[:, trial_idx, :]       # (6, 1280)
        trial_smooth_s3      = segments_smooth_s3[:, trial_idx, :]       # (6, 1280)
        trial_downsampled_d2 = segments_downsampled_d2[:, trial_idx, :]  # (6, 1280)
        trial_downsampled_d3 = segments_downsampled_d3[:, trial_idx, :]  # (6, 1280)

        # 5ì±„ë„ë¡œ ìŠ¤íƒ: (6, 5, 1280)
        emcnn_input = np.stack([
            trial_identity,
            trial_smooth_s2,
            trial_smooth_s3,
            trial_downsampled_d2,
            trial_downsampled_d3
        ], axis=1)

        # ê°ì • ë¼ë²¨ (ì˜ˆ: [valence, arousal])ì„ íŒŒì¼ëª…ì— í¬í•¨
        emotion_label = labels[trial_idx]
        trial_filename = (
            f"s{subject_id:02d}_trial_{trial_idx:02d}_"
            f"label_{emotion_label}.npy"
        )
        trial_filepath = os.path.join(output_dir, trial_filename)
        np.save(trial_filepath, emcnn_input)

    print(f"âœ… {subject_filename} ë³€í™˜ ì™„ë£Œ: ê° trialë‹¹ shape={emcnn_input.shape}, ì´ 40ê°œ trial ì €ì¥ë¨.")

print("ğŸ¯ ëª¨ë“  ë°ì´í„° ë³€í™˜ ì™„ë£Œ! ì´ì œ (6, 5, 1280) í˜•íƒœì˜ 10ì´ˆ ë‹¨ìœ„ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")