"""
DEAP ë°ì´í„°ì…‹ (EEG, PPS) ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ê°ì • ë¶„ë¥˜ ëª¨ë¸
- EEG ë°ì´í„°: (40, 32, 128) â†’ ëª¨ë¸ ì…ë ¥: (40, 32, 128, 1)
- PPS ë°ì´í„°: (40, 8, 128) â†’ ëª¨ë¸ ì…ë ¥: (40, 8, 128, 1)
- ë¼ë²¨: (40,) (Negative: 0, Positive: 1, Neutral: 2)
- ê° íŒŒì¼ì—ëŠ” 40ê°œì˜ 1ì´ˆ ìƒ˜í”Œì´ ì €ì¥ë˜ì–´ ìˆìœ¼ë©°, ì´ë“¤ ìƒ˜í”Œì€ ë¼ë²¨ íŒŒì¼ê³¼ 1:1 ë§¤ì¹­ë©ë‹ˆë‹¤.
"""

import os
# os.environ["TF_FORCE_GPU_ALLOW_GROWTH"] = "true"
# os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"

import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import (
    Conv2D, Dense, Flatten, Dropout, AveragePooling2D, DepthwiseConv2D,
    LayerNormalization, MultiHeadAttention, Input, Lambda, Add, Concatenate, Softmax
)
from tensorflow.keras.models import Model
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import classification_report

def limit_gpu_memory(memory_limit_mib=8000):
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            tf.config.experimental.set_virtual_device_configuration(
                gpus[0],
                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit_mib)]
            )
            print(f"GPU memory limited to {memory_limit_mib} MiB.")
        except RuntimeError as e:
            print(e)
    else:
        print("No GPU available, using CPU.")

limit_gpu_memory(8000)

# =============================================================================
# í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ê²½ë¡œ ì„¤ì •
# =============================================================================
BATCH_SIZE = 32
EPOCHS = 150
LEARNING_RATE = 1e-4

# ë°ì´í„° ê²½ë¡œ (í•„ìš”ì— ë”°ë¼ ìˆ˜ì •)
EEG_DATA_PATH = "/home/bcml1/2025_EMOTION/DEAP_EEG2"
PPS_DATA_PATH = "/home/bcml1/2025_EMOTION/DEAP_PPS2"  # PPS ì‹ í˜¸ íŒŒì¼ë“¤ì´ ì €ì¥ëœ ê²½ë¡œ
LABELS_PATH  = "/home/bcml1/2025_EMOTION/DEAP_three_labels"
SAVE_PATH    = "/home/bcml1/sigenv/_3ì£¼ì°¨_new_EEG+PPS_CNN/result1"
os.makedirs(SAVE_PATH, exist_ok=True)

# =============================================================================
# 1. Dualâ€‘Stream Feature Extractor (EEG & PPS)
# =============================================================================
def create_dual_stream_feature_extractor():
    """
    EEGì™€ PPSë¥¼ ê°ê° CNNìœ¼ë¡œ íŠ¹ì§• ì¶”ì¶œ
    - EEG Branch: ì…ë ¥ (32, 128, 1)
    - PPS Branch: ì…ë ¥ (8, 128, 1)
    """
    ## EEG Branch
    eeg_input = Input(shape=(32, 128, 1), name="EEG_Input")
    x = Conv2D(filters=16, kernel_size=(4,16), strides=(2,8), padding='valid', activation='relu')(eeg_input)
    x = DepthwiseConv2D(kernel_size=(6,6), strides=(3,3), padding='valid', activation='relu')(x)
    x = AveragePooling2D(pool_size=(2,2), strides=(2,2))(x)
    x = Conv2D(filters=32, kernel_size=(1,1), strides=(1,1), activation='relu')(x)
    x = Flatten()(x)
    x = Dropout(0.25)(x)
    eeg_output = Dense(128, activation="relu")(x)
    
    ## PPS Branch
    pps_input = Input(shape=(8, 128, 1), name="PPS_Input")
    y = Conv2D(filters=16, kernel_size=(1,16), strides=(1,8), padding='valid', activation='relu')(pps_input)
    y = DepthwiseConv2D(kernel_size=(2,6), strides=(2,3), padding='valid', activation='relu')(y)
    y = AveragePooling2D(pool_size=(2,2), strides=(2,2))(y)
    y = Conv2D(filters=32, kernel_size=(1,1), strides=(1,1), activation='relu')(y)
    y = Flatten()(y)
    y = Dropout(0.25)(y)
    pps_output = Dense(128, activation="relu")(y)
    
    model = Model(inputs=[eeg_input, pps_input], outputs=[eeg_output, pps_output],
                  name="DualStreamFeatureExtractor")
    return model

# =============================================================================
# 2. Interâ€‘Modality Fusion Module (Crossâ€‘Modal Transformer)
# =============================================================================
def create_inter_modality_fusion(eeg_features, pps_features, num_heads=4, d_model=128, dropout_rate=0.25):
    """
    EEGì™€ PPS ê°„ì˜ ìƒí˜¸ê´€ê³„ë¥¼ í•™ìŠµí•˜ëŠ” Crossâ€‘Modal Transformer
    """
    # EEG â†’ PPS
    eeg_query = Dense(d_model)(eeg_features)
    pps_key_value = Dense(d_model)(pps_features)
    eeg_query = Lambda(lambda x: tf.expand_dims(x, axis=1))(eeg_query)
    pps_key_value = Lambda(lambda x: tf.expand_dims(x, axis=1))(pps_key_value)
    
    cross_att_1 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model, name="CrossModal_EEG_to_PPS")(
        query=eeg_query, key=pps_key_value, value=pps_key_value)
    cross_att_1 = Dropout(dropout_rate)(cross_att_1)
    cross_att_1 = Add()([eeg_query, cross_att_1])
    cross_att_1 = LayerNormalization(epsilon=1e-6)(cross_att_1)
    cross_att_1 = Lambda(lambda x: tf.squeeze(x, axis=1))(cross_att_1)
    
    # PPS â†’ EEG
    pps_query = Dense(d_model)(pps_features)
    pps_query = Lambda(lambda x: tf.expand_dims(x, axis=1))(pps_query)
    eeg_key_value_2 = Dense(d_model)(eeg_features)
    eeg_key_value_2 = Lambda(lambda x: tf.expand_dims(x, axis=1))(eeg_key_value_2)
    
    cross_att_2 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model, name="CrossModal_PPS_to_EEG")(
        query=pps_query, key=eeg_key_value_2, value=eeg_key_value_2)
    cross_att_2 = Dropout(dropout_rate)(cross_att_2)
    cross_att_2 = Add()([pps_query, cross_att_2])
    cross_att_2 = LayerNormalization(epsilon=1e-6)(cross_att_2)
    cross_att_2 = Lambda(lambda x: tf.squeeze(x, axis=1))(cross_att_2)
    
    fused_features = Concatenate(axis=-1)([cross_att_1, cross_att_2])
    fused_features = Dense(d_model, activation="relu", name="Fused_Linear")(fused_features)
    
    # Self-Attention Fusion
    fused_expanded = Lambda(lambda x: tf.expand_dims(x, axis=1))(fused_features)
    self_att = MultiHeadAttention(num_heads=num_heads, key_dim=d_model, name="SelfAttentionFusion")(
        query=fused_expanded, key=fused_expanded, value=fused_expanded)
    self_att = Dropout(dropout_rate)(self_att)
    self_att = Add()([fused_expanded, self_att])
    self_att = LayerNormalization(epsilon=1e-6)(self_att)
    self_att = Lambda(lambda x: tf.squeeze(x, axis=1))(self_att)
    return self_att

# =============================================================================
# 3. Intraâ€‘Modality Encoding Module
# =============================================================================
def create_intra_modality_encoding(eeg_features, pps_features, num_heads=4, d_model=128, dropout_rate=0.25):
    """
    EEGì™€ PPS ê°ê°ì˜ ê³ ìœ  íŠ¹ì„±ì„ ë³´ì¡´ ë° ê°•í™”í•˜ëŠ” Intraâ€‘Modal Encoding
    """
    # EEG Self-Attention
    eeg_expanded = Lambda(lambda x: tf.expand_dims(x, axis=1))(eeg_features)
    eeg_self_att = MultiHeadAttention(num_heads=num_heads, key_dim=d_model, name="SelfAttention_EEG")(
        query=eeg_expanded, key=eeg_expanded, value=eeg_expanded)
    eeg_self_att = Dropout(dropout_rate)(eeg_self_att)
    eeg_self_att = Add()([eeg_expanded, eeg_self_att])
    eeg_self_att = LayerNormalization(epsilon=1e-6)(eeg_self_att)
    eeg_self_att = Lambda(lambda x: tf.squeeze(x, axis=1))(eeg_self_att)
    
    # PPS Self-Attention
    pps_expanded = Lambda(lambda x: tf.expand_dims(x, axis=1))(pps_features)
    pps_self_att = MultiHeadAttention(num_heads=num_heads, key_dim=d_model, name="SelfAttention_PPS")(
        query=pps_expanded, key=pps_expanded, value=pps_expanded)
    pps_self_att = Dropout(dropout_rate)(pps_self_att)
    pps_self_att = Add()([pps_expanded, pps_self_att])
    pps_self_att = LayerNormalization(epsilon=1e-6)(pps_self_att)
    pps_self_att = Lambda(lambda x: tf.squeeze(x, axis=1))(pps_self_att)
    
    return eeg_self_att, pps_self_att

# =============================================================================
# 4. ì „ì²´ ëª¨ë¸ êµ¬ì„± (EEG, PPS ì…ë ¥ â†’ Dualâ€‘Stream Extraction â†’ Fusion â†’ ë¶„ë¥˜)
# =============================================================================
def build_combined_model(num_classes=3):
    """
    EEGì™€ PPS ë°ì´í„°ë¥¼ ë°›ì•„ì„œ  
      - Dualâ€‘Stream Feature Extraction  
      - Crossâ€‘Modal Fusion  
      - Intraâ€‘Modal Encoding  
    ì„ ê±°ì³ ìµœì¢… ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” ëª¨ë¸ êµ¬ì„±
    """
    eeg_input = Input(shape=(32, 128, 1), name="EEG_Input")
    pps_input = Input(shape=(8, 128, 1), name="PPS_Input")
    
    dual_extractor = create_dual_stream_feature_extractor()
    eeg_features, pps_features = dual_extractor([eeg_input, pps_input])
    
    fused_features = create_inter_modality_fusion(eeg_features, pps_features)
    eeg_encoded, pps_encoded = create_intra_modality_encoding(eeg_features, pps_features)
    
    inter_classification = Dense(num_classes, activation="softmax", name="Inter_Classification")(fused_features)
    eeg_classification   = Dense(num_classes, activation="softmax", name="EEG_Classification")(eeg_encoded)
    pps_classification   = Dense(num_classes, activation="softmax", name="PPS_Classification")(pps_encoded)
    
    concat_features = Concatenate()([fused_features, eeg_encoded, pps_encoded])
    weights_logits = Dense(units=3, activation=None, name="Weight_Logits")(concat_features)
    weights = Softmax(axis=-1, name="Weight_Softmax")(weights_logits)
    
    model = Model(inputs=[eeg_input, pps_input],
                  outputs=[inter_classification, eeg_classification, pps_classification, weights],
                  name="Multimodal_Emotion_Classifier")
    return model

# =============================================================================
# 5. Custom í•™ìŠµ ë‹¨ê³„ í¬í•¨ ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜
# =============================================================================
class MultimodalEmotionClassifier(tf.keras.Model):
    def __init__(self, base_model, **kwargs):
        super(MultimodalEmotionClassifier, self).__init__(**kwargs)
        self.base_model = base_model

    def call(self, inputs, training=False):
        return self.base_model(inputs, training=training)

    def train_step(self, data):
        x, y = data
        if isinstance(y, dict):
            y_true = y["Inter_Classification"]
        else:
            y_true = y

        with tf.GradientTape() as tape:
            inter_pred, eeg_pred, pps_pred, _ = self(x, training=True)
            loss_inter = tf.keras.losses.sparse_categorical_crossentropy(y_true, inter_pred)
            loss_eeg   = tf.keras.losses.sparse_categorical_crossentropy(y_true, eeg_pred)
            loss_pps   = tf.keras.losses.sparse_categorical_crossentropy(y_true, pps_pred)
            loss = tf.reduce_mean((loss_inter + loss_eeg + loss_pps) / 3.0)

        trainable_vars = self.trainable_variables
        gradients = tape.gradient(loss, trainable_vars)
        self.optimizer.apply_gradients(zip(gradients, trainable_vars))
        self.compiled_metrics.update_state(y_true, inter_pred)
        results = {m.name: m.result() for m in self.metrics}
        results.update({"loss": loss})
        return results
    
    def test_step(self, data):
        x, y = data
        y_true = y["Inter_Classification"] if isinstance(y, dict) else y
        inter_pred, eeg_pred, pps_pred, _ = self(x, training=False)
        loss_inter = tf.keras.losses.sparse_categorical_crossentropy(y_true, inter_pred)
        loss_eeg   = tf.keras.losses.sparse_categorical_crossentropy(y_true, eeg_pred)
        loss_pps   = tf.keras.losses.sparse_categorical_crossentropy(y_true, pps_pred)
        loss = tf.reduce_mean((loss_inter + loss_eeg + loss_pps) / 3.0)
        self.compiled_metrics.update_state(y_true, inter_pred)
        metric_results = {m.name: m.result() for m in self.metrics}
        results = {"accuracy": metric_results.get("accuracy", 0.0), "loss": loss}
        return results

# =============================================================================
# 6. (Optional) í´ë˜ìŠ¤ ë¹ˆë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚° (í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
# =============================================================================
def compute_class_weights(labels, num_classes=3):
    class_counts = np.bincount(labels, minlength=num_classes)
    total = np.sum(class_counts)
    class_weights = total / (num_classes * class_counts)
    class_weights /= np.max(class_weights)
    return class_weights.astype(np.float32)

# =============================================================================
# 7. ë°ì´í„° ì¦ê°• í•¨ìˆ˜ (EEGëŠ” noise_std=0.01, PPSëŠ” noise_std=0.005)
# =============================================================================
def augment_sample(eeg_sample, pps_sample, noise_std_eeg=0.01, noise_std_pps=0.005):
    """
    í•˜ë‚˜ì˜ EEG/PPS ìƒ˜í”Œì— ëŒ€í•´ ë¬´ì‘ìœ„ë¡œ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€ ë˜ëŠ” ì‹ í˜¸ ë°˜ì „ì„ ì ìš©.
    """
    aug_type = np.random.choice([0, 1])
    if aug_type == 0:
        eeg_aug = eeg_sample + np.random.normal(0, noise_std_eeg, size=eeg_sample.shape)
        pps_aug = pps_sample + np.random.normal(0, noise_std_pps, size=pps_sample.shape)
    else:
        eeg_aug = -eeg_sample
        pps_aug = -pps_sample
    return eeg_aug, pps_aug

def balance_data(train_eeg, train_pps, train_labels):
    """
    ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œ ê° í´ë˜ìŠ¤ì˜ ìˆ˜ë¥¼ ë™ì¼í•˜ê²Œ ë§ì¶”ê¸° ìœ„í•´ oversampling (with replacement)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    unique, counts = np.unique(train_labels, return_counts=True)
    max_count = np.max(counts)
    balanced_eeg = []
    balanced_pps = []
    balanced_labels = []
    for cls in unique:
        indices = np.where(train_labels == cls)[0]
        if len(indices) < max_count:
            oversampled = np.random.choice(indices, size=max_count, replace=True)
        else:
            oversampled = indices
        balanced_eeg.append(train_eeg[oversampled])
        balanced_pps.append(train_pps[oversampled])
        balanced_labels.append(train_labels[oversampled])
    balanced_eeg = np.concatenate(balanced_eeg, axis=0)
    balanced_pps = np.concatenate(balanced_pps, axis=0)
    balanced_labels = np.concatenate(balanced_labels, axis=0)
    perm = np.random.permutation(balanced_labels.shape[0])
    return balanced_eeg[perm], balanced_pps[perm], balanced_labels[perm]

def augment_all_data(train_eeg, train_pps, train_labels, noise_std_eeg=0.01, noise_std_pps=0.005, factor=5):
    """
    ê° ìƒ˜í”Œë§ˆë‹¤ (factor-1)ê°œì˜ ì¦ê°• ìƒ˜í”Œì„ ìƒì„±í•˜ì—¬ ì›ë³¸ ë°ì´í„°ì™€ í•¨ê»˜ ì´ factorë°° í¬ê¸°ì˜ ë°ì´í„°ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    """
    N = train_eeg.shape[0]
    aug_eeg = []
    aug_pps = []
    aug_labels = []
    for i in range(N):
        for _ in range(factor - 1):
            e_aug, p_aug = augment_sample(train_eeg[i], train_pps[i], noise_std_eeg, noise_std_pps)
            aug_eeg.append(e_aug)
            aug_pps.append(p_aug)
            aug_labels.append(train_labels[i])
    aug_eeg = np.array(aug_eeg)
    aug_pps = np.array(aug_pps)
    aug_labels = np.array(aug_labels)
    all_eeg = np.concatenate([train_eeg, aug_eeg], axis=0)
    all_pps = np.concatenate([train_pps, aug_pps], axis=0)
    all_labels = np.concatenate([train_labels, aug_labels], axis=0)
    perm = np.random.permutation(all_labels.shape[0])
    return all_eeg[perm], all_pps[perm], all_labels[perm]

# =============================================================================
# 8. ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# =============================================================================
def load_multimodal_data(subject):
    """
    subject: ì˜ˆ) "s01", "s02", ..., "s22"
    
    ê° í”¼í—˜ìë³„ë¡œ,
      - EEG íŒŒì¼: {subject}_eeg_signals_segment_XX.npy, ê° íŒŒì¼ shape: (40, 32, 128)
      - PPS íŒŒì¼: {subject}_pps_signals_segment_XX.npy, ê° íŒŒì¼ shape: (40, 8, 128)
      - ë¼ë²¨ íŒŒì¼: {subject}_three_labels.npy, shape: (40,)
      
    ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ íŒŒì¼ì„ ìˆœì°¨ì ìœ¼ë¡œ ë¡œë“œí•œ í›„ axis=0ìœ¼ë¡œ concatenateí•˜ì—¬ ìµœì¢… ë°ì´í„°ì…‹ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
    
    ìµœì¢… ë°ì´í„°:
      - EEG: (N, 32, 128, 1)
      - PPS: (N, 8, 128, 1)
      - N = (ì„¸ê·¸ë¨¼íŠ¸ íŒŒì¼ ìˆ˜) * 40
      - ë¼ë²¨: ê° ì„¸ê·¸ë¨¼íŠ¸ë§ˆë‹¤ ë™ì¼í•˜ë¯€ë¡œ (N,) shape
    """
    import glob
    eeg_pattern = os.path.join(EEG_DATA_PATH, f"{subject}_eeg_signals_segment_*.npy")
    pps_pattern = os.path.join(PPS_DATA_PATH, f"{subject}_pps_signals_segment_*.npy")
    
    eeg_files = sorted(glob.glob(eeg_pattern))
    pps_files = sorted(glob.glob(pps_pattern))
    
    if len(eeg_files) == 0 or len(pps_files) == 0:
        raise FileNotFoundError(f"{subject}ì— í•´ë‹¹í•˜ëŠ” EEG ë˜ëŠ” PPS íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    if len(eeg_files) != len(pps_files):
        print("ê²½ê³ : EEGì™€ PPS íŒŒì¼ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    eeg_segments = []
    pps_segments = []
    
    for eeg_file, pps_file in zip(eeg_files, pps_files):
        eeg_data = np.load(eeg_file)  # shape: (40, 32, 128)
        eeg_segments.append(eeg_data)
        
        pps_data = np.load(pps_file)  # shape: (40, 8, 128)
        pps_segments.append(pps_data)
    
    eeg_array = np.concatenate(eeg_segments, axis=0)  # (ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜*40, 32, 128)
    pps_array = np.concatenate(pps_segments, axis=0)    # (ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜*40, 8, 128)
    
    eeg_array = np.expand_dims(eeg_array, axis=-1)       # (N, 32, 128, 1)
    pps_array = np.expand_dims(pps_array, axis=-1)         # (N, 8, 128, 1)
    
    label_file = os.path.join(LABELS_PATH, f"{subject}_three_labels.npy")
    if not os.path.exists(label_file):
        raise FileNotFoundError(f"ë¼ë²¨ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {label_file}")
    labels = np.load(label_file)  # (40,)
    
    S = len(eeg_files)
    labels_repeated = np.tile(labels, S)  # (S*40,)
    
    train_eeg, test_eeg, train_pps, test_pps, train_labels, test_labels = train_test_split(
        eeg_array, pps_array, labels_repeated, test_size=0.2, random_state=42, stratify=labels_repeated)
    
    return train_eeg, train_pps, train_labels, test_eeg, test_pps, test_labels

# =============================================================================
# 9. ì»¤ìŠ¤í…€ ì½œë°±: validation accuracyê°€ 7 ì—í¬í¬ ë™ì•ˆ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ìµœê³  ê°€ì¤‘ì¹˜ ë³µì› í›„ í•™ìŠµ ì¤‘ë‹¨
# =============================================================================
class RestoreBestWeightsOnDrop(tf.keras.callbacks.Callback):
    def __init__(self, monitor='val_accuracy', min_delta=0.001, patience=7, verbose=1):
        super(RestoreBestWeightsOnDrop, self).__init__()
        self.monitor = monitor
        self.min_delta = min_delta
        self.patience = patience
        self.verbose = verbose
        self.best = -np.Inf
        self.best_weights = None
        self.wait = 0

    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        current = logs.get(self.monitor)
        if current is None:
            return
        if current > self.best + self.min_delta:
            self.best = current
            self.best_weights = self.model.get_weights()
            self.wait = 0
        else:
            self.wait += 1
            if self.wait >= self.patience:
                if self.verbose:
                    print(f"\nValidation {self.monitor} did not improve for {self.patience} epochs. Stopping training and restoring best weights.")
                self.model.set_weights(self.best_weights)
                self.model.stop_training = True

# =============================================================================
# 10. 10-Fold Cross Validationì„ ì ìš©í•œ í•™ìŠµ ë° í‰ê°€
# =============================================================================
def train_multimodal():
    from sklearn.model_selection import StratifiedKFold
    subjects = [f"s{str(i).zfill(2)}" for i in range(1, 23)]
    for subject in subjects:
        print(f"\n==== {subject} ë°ì´í„° ë¡œë“œ ====")
        try:
            train_eeg, train_pps, train_labels, test_eeg, test_pps, test_labels = load_multimodal_data(subject)
        except Exception as e:
            print(f"{subject} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            continue

        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
        fold_val_scores = []
        fold = 1
        for train_index, val_index in skf.split(train_eeg, train_labels):
            print(f"\n---- {subject} Fold {fold} ----")
            fold_train_eeg, fold_valid_eeg = train_eeg[train_index], train_eeg[val_index]
            fold_train_pps, fold_valid_pps = train_pps[train_index], train_pps[val_index]
            fold_train_labels, fold_valid_labels = train_labels[train_index], train_labels[val_index]
            
            # ë°ì´í„° ë°¸ëŸ°ì‹± ë° ì¦ê°• (í´ë˜ìŠ¤ ê· í˜• ë§ì¶¤ í›„ ì „ì²´ ë°ì´í„° 5ë°° ì¦ê°•)
            fold_train_eeg, fold_train_pps, fold_train_labels = balance_data(fold_train_eeg, fold_train_pps, fold_train_labels)
            fold_train_eeg, fold_train_pps, fold_train_labels = augment_all_data(
                fold_train_eeg, fold_train_pps, fold_train_labels,
                noise_std_eeg=0.01, noise_std_pps=0.005, factor=5)
            
            print(f"Fold {fold} í•™ìŠµ ìƒ˜í”Œ: EEG {fold_train_eeg.shape}, PPS {fold_train_pps.shape}, ë¼ë²¨ {fold_train_labels.shape}")
            
            # í‘œì¤€ SparseCategoricalCrossentropyë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            base_model = build_combined_model(num_classes=3)
            model = MultimodalEmotionClassifier(base_model)
            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
                          loss=tf.keras.losses.SparseCategoricalCrossentropy(),
                          metrics=["accuracy"])
            model.summary()
            
            callbacks = [
                RestoreBestWeightsOnDrop(monitor='val_accuracy', min_delta=0.001, patience=7, verbose=1),
                tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=7, min_delta=0.001, restore_best_weights=True, verbose=1),
                tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, verbose=1)
            ]
            
            history = model.fit(
                [fold_train_eeg, fold_train_pps], fold_train_labels,
                validation_data=([fold_valid_eeg, fold_valid_pps], fold_valid_labels),
                epochs=EPOCHS,
                batch_size=BATCH_SIZE,
                callbacks=callbacks,
                verbose=1
            )
            
            scores = model.evaluate([fold_valid_eeg, fold_valid_pps], fold_valid_labels, verbose=0)
            print(f"Fold {fold} validation metrics: {scores}")
            fold_val_scores.append(scores)
            fold += 1
        
        fold_val_scores = np.array(fold_val_scores)
        print(f"\n==== {subject} 10-Fold CV í‰ê·  Validation Metrics (loss, accuracy): {np.mean(fold_val_scores, axis=0)} ====")
        
        # ìµœì¢… test í‰ê°€ (í•„ìš” ì‹œ retraining í›„ í‰ê°€)
        base_model = build_combined_model(num_classes=3)
        model = MultimodalEmotionClassifier(base_model)
        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
                      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
                      metrics=["accuracy"])
        train_eeg_aug, train_pps_aug, train_labels_aug = balance_data(train_eeg, train_pps, train_labels)
        train_eeg_aug, train_pps_aug, train_labels_aug = augment_all_data(
            train_eeg_aug, train_pps_aug, train_labels_aug,
            noise_std_eeg=0.01, noise_std_pps=0.005, factor=5)
        model.fit([train_eeg_aug, train_pps_aug], train_labels_aug,
                  epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)
        predictions = model.predict([test_eeg, test_pps])
        inter_pred = predictions[0]
        predicted_labels = np.argmax(inter_pred, axis=-1)
        report = classification_report(test_labels, predicted_labels,
                                       target_names=["Negative", "Positive", "Neutral"],
                                       labels=[0,1,2], zero_division=0)
        print(f"\nğŸ“Š {subject} í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸\n{report}")
        
        subject_save_path = os.path.join(SAVE_PATH, subject)
        os.makedirs(subject_save_path, exist_ok=True)
        weight_path = os.path.join(subject_save_path, f"{subject}_multimodal_model.weights.h5")
        model.save_weights(weight_path)
        print(f"âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥: {weight_path}")
        report_path = os.path.join(subject_save_path, f"{subject}_test_report.txt")
        with open(report_path, "w") as f:
            f.write(report)
        print(f"âœ… í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")

if __name__ == "__main__":
    train_multimodal()
