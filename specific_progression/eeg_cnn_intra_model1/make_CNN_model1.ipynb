{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388267f8-f9e6-4694-86d7-b36fa6bf003d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 08:08:28.387240: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-29 08:08:29.056973: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc31cf2-aebb-4929-bc0f-ebc97c00404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 설정 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 08:08:29.775291: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-29 08:08:29.814383: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-29 08:08:29.818326: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow 로그 설정\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# GPU 설정 및 라이브러리 로드 확인\n",
    "def configure_gpu():\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"GPU 설정 완료\")\n",
    "        else:\n",
    "            print(\"GPU를 사용할 수 없습니다. TensorFlow 설치 및 환경을 확인하세요.\")\n",
    "    except Exception as e:\n",
    "        print(f\"GPU 설정 중 오류 발생: {e}\")\n",
    "\n",
    "configure_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e166b2e-fa62-4a69-904b-c54183a79147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "data_dir = \"/home/bcml1/sigenv/eeg_band_split\"  # 실제 데이터 경로로 변경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c913dd-96b3-4c80-b197-9a5e3e6481a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data function - assumes EEG data is preprocessed and split by participant\n",
    "def load_data():\n",
    "    # Placeholder function to load EEG data\n",
    "    # X should be a 4D array: [samples, channels, height, width]\n",
    "    # y should be a 1D array: [samples]\n",
    "    # Replace this with actual data loading logic\n",
    "    X = np.load('eeg_data.npy')\n",
    "    y = np.load('eeg_labels.npy')\n",
    "    participants = np.load('participant_ids.npy')  # Array indicating participant ID for each sample\n",
    "    return X, y, participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30deda39-e89c-4910-a5b4-2aebe132cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model structure\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d42aabc-bcd6-42f0-a2c4-0ff94faac24b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'eeg_data.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Main script\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m     X, y, participants \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y))\n\u001b[1;32m      6\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# Assuming data is already reshaped appropriately\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Placeholder function to load EEG data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# X should be a 4D array: [samples, channels, height, width]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# y should be a 1D array: [samples]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Replace this with actual data loading logic\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meeg_data.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg_labels.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m     participants \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparticipant_ids.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Array indicating participant ID for each sample\u001b[39;00m\n",
      "File \u001b[0;32m~/sigenv/lib/python3.12/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'eeg_data.npy'"
     ]
    }
   ],
   "source": [
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    X, y, participants = load_data()\n",
    "    \n",
    "    num_classes = len(np.unique(y))\n",
    "    input_shape = X.shape[1:]  # Assuming data is already reshaped appropriately\n",
    "    y_categorical = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, test_index in loo.split(np.unique(participants)):\n",
    "        train_participants = np.unique(participants)[train_index]\n",
    "        test_participant = np.unique(participants)[test_index][0]\n",
    "\n",
    "        # Split data by participants\n",
    "        train_mask = np.isin(participants, train_participants)\n",
    "        test_mask = participants == test_participant\n",
    "\n",
    "        X_train, X_test = X[train_mask], X[test_mask]\n",
    "        y_train, y_test = y_categorical[train_mask], y_categorical[test_mask]\n",
    "\n",
    "        # Create and train model\n",
    "        model = create_cnn_model(input_shape, num_classes)\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "        # Evaluate model\n",
    "        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        print(f\"Test participant: {test_participant}, Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    print(f\"Mean accuracy across participants: {np.mean(accuracy_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55dc4391-4f50-43fd-b775-668e08ab5d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "# 학습 결과 저장\n",
    "model.save(\"eeg_cnn_model_mj.h5\")\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bebe4ec7-953c-49b6-af5b-5466ac56f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 결과 평가\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meeg_cnn_model_mj.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mX_test\u001b[49m, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    " # 결과 평가\n",
    "model = tf.keras.models.load_model(\"eeg_cnn_model_mj.h5\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1575d6-c69b-4de6-ab9f-1dc9b470ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 예측\n",
    "test_sample = X_test[0]  # 임의의 샘플\n",
    "test_sample = np.expand_dims(test_sample, axis=0)  # 배치 차원 추가\n",
    "prediction = model.predict(test_sample)\n",
    "\n",
    "\n",
    "#테스트 데이터로 코드를 예측하는 부분 구현 필요\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Prediction (0=negative, 1=positive): {prediction[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2f569-8aba-4b30-992c-f0bcafaf9767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd1f6f-2411-4639-bf75-e0ac3e58e229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
