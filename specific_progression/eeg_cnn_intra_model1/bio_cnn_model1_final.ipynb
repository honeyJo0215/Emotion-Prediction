{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "40bf51b0-1d8e-40a7-b85c-41d4e2989b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# TensorFlow 로그 레벨 설정\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' #순서 지켜야함\n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Failed to set memory growth: {e}\")\n",
    "else:\n",
    "    print(\"No GPU devices found. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d99c5005-e7f7-49f4-9ca2-bf5f0dfb8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # 데이터 파일 로드\n",
    "    data_dir = \"/home/bcml1/2025_EMOTION/DEAP_EEG/ch_BPF\"\n",
    "    #모델 3,4일때는 /home/bcml1/sigenv/eeg_band_split임\n",
    "    \n",
    "    # 파일 로드 및 병합\n",
    "    files = [f for f in os.listdir(data_dir) if f.endswith('.npy')]\n",
    "    \n",
    "    X_list, y_list, participants_list = [], [], []\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            data = np.load(os.path.join(data_dir, file))\n",
    "            \n",
    "            # 파일별로 X, y, participants 추가\n",
    "            X_list.append(data)\n",
    "\n",
    "            # 파일명에서 참여자와 라벨 추출\n",
    "            participant = file.split('_')[0]  # 예: s01\n",
    "            label = file.split('_')[1]       # 예: negative\n",
    "\n",
    "            participants_list.extend([participant] * data.shape[0])  # 참여자 반복\n",
    "            y_list.extend([label] * data.shape[0])  # 라벨 반복\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {file}: {e}\")\n",
    "\n",
    "    # 배열로 변환. 병합\n",
    "    X = np.concatenate(X_list, axis=0)  # 데이터를 하나의 배열로 병합\n",
    "    y = np.array(y_list)\n",
    "    participants = np.array(participants_list)\n",
    "    \n",
    "    # 크기 확인\n",
    "    if len(X) != len(y) or len(X) != len(participants):\n",
    "        raise ValueError(f\"Mismatch in data lengths: X={len(X)}, y={len(y)}, participants={len(participants)}\")\n",
    "\n",
    "    return X, y, participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3de0a3a9-f3f2-4c3a-921e-e181156b6b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 정의\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),  # 명시적으로 Input 레이어 추가\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b39105c7-86f4-449c-b383-f6b2ca3c877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 최적화 기능 추가\n",
    "#def get_batch_size():\n",
    "#    return 32  # 배치 크기를 유동적으로 변경 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c1674e88-25b4-41da-ad5c-a6b2cdf117e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (322, 8, 5120), y shape: (322,), participants shape: (322,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 11:26:44.748424: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-29 11:26:44.751510: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-29 11:26:44.753997: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "cudaSetDevice() on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean accuracy across participants: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(accuracy_scores)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mpredict_test_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[79], line 36\u001b[0m, in \u001b[0;36mpredict_test_samples\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y_categorical[train_mask], y_categorical[test_mask]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 모델 생성 및 학습\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_cnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#batch_size = get_batch_size()\u001b[39;00m\n\u001b[1;32m     38\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[77], line 8\u001b[0m, in \u001b[0;36mcreate_cnn_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_cnn_model\u001b[39m(input_shape, num_classes):\n\u001b[1;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m      4\u001b[0m         Input(shape\u001b[38;5;241m=\u001b[39minput_shape),  \u001b[38;5;66;03m# 명시적으로 Input 레이어 추가\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m         BatchNormalization(),\n\u001b[1;32m      7\u001b[0m         MaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m----> 8\u001b[0m         \u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m         Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     11\u001b[0m         BatchNormalization(),\n\u001b[1;32m     12\u001b[0m         MaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m     13\u001b[0m         Dropout(\u001b[38;5;241m0.25\u001b[39m),\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m         Flatten(),\n\u001b[1;32m     16\u001b[0m         Dense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     17\u001b[0m         BatchNormalization(),\n\u001b[1;32m     18\u001b[0m         Dropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m     19\u001b[0m         Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m     ])\n\u001b[1;32m     21\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/sigenv/lib/python3.12/site-packages/keras/src/layers/regularization/dropout.py:53\u001b[0m, in \u001b[0;36mDropout.__init__\u001b[0;34m(self, rate, noise_shape, seed, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_shape \u001b[38;5;241m=\u001b[39m noise_shape\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed_generator \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeedGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_masking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/sigenv/lib/python3.12/site-packages/keras/src/random/seed_generator.py:75\u001b[0m, in \u001b[0;36mSeedGenerator.__init__\u001b[0;34m(self, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mconvert_to_tensor([seed, \u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, caller\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_seed_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed_generator_state\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sigenv/lib/python3.12/site-packages/keras/src/backend/common/variables.py:170\u001b[0m, in \u001b[0;36mVariable.__init__\u001b[0;34m(self, initializer, shape, dtype, trainable, autocast, aggregation, name)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(initializer):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_shape(shape)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_with_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(initializer)\n",
      "File \u001b[0;32m~/sigenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:47\u001b[0m, in \u001b[0;36mVariable._initialize_with_initializer\u001b[0;34m(self, initializer)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_with_initializer\u001b[39m(\u001b[38;5;28mself\u001b[39m, initializer):\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_aggregation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sigenv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/sigenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:48\u001b[0m, in \u001b[0;36mVariable._initialize_with_initializer.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_with_initializer\u001b[39m(\u001b[38;5;28mself\u001b[39m, initializer):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(\n\u001b[0;32m---> 48\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43minitializer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     49\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype,\n\u001b[1;32m     50\u001b[0m         trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable,\n\u001b[1;32m     51\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     52\u001b[0m         aggregation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_aggregation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregation),\n\u001b[1;32m     53\u001b[0m     )\n",
      "File \u001b[0;32m~/sigenv/lib/python3.12/site-packages/keras/src/random/seed_generator.py:72\u001b[0m, in \u001b[0;36mSeedGenerator.__init__.<locals>.seed_initializer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mseed_initializer\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     71\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sigenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:141\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mis_tensor(x):\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_int_dtype(dtype):\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;66;03m# TensorFlow conversion is stricter than other backends, it does not\u001b[39;00m\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;66;03m# allow ints for bools or floats for ints. We convert without dtype\u001b[39;00m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;66;03m# and cast instead.\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcast(x, dtype)\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mInternalError\u001b[0m: cudaSetDevice() on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 예측 함수\n",
    "def predict_test_samples():\n",
    "    X, y, participants = load_data()\n",
    "\n",
    "    # 데이터 크기 확인\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}, participants shape: {participants.shape}\")\n",
    "\n",
    "    # participants 배열의 크기가 X와 y의 첫 번째 축과 일치하지 않는 경우 처리\n",
    "    if participants.shape[0] != X.shape[0] or participants.shape[0] != y.shape[0]:\n",
    "        raise ValueError(\"Mismatch in dimensions: 'participants', 'X', and 'y' must have the same number of samples.\")\n",
    "\n",
    "    # 문자열 라벨을 숫자형 라벨로 매핑\n",
    "    unique_labels = np.unique(y)\n",
    "    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    y_int = np.array([label_to_int[label] for label in y])\n",
    "\n",
    "    num_classes = len(unique_labels)\n",
    "    input_shape = X.shape[1:]  # 데이터가 올바르게 reshape되었다고 가정\n",
    "    y_categorical = to_categorical(y_int, num_classes=num_classes)\n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, test_index in loo.split(np.unique(participants)):\n",
    "        train_participants = np.unique(participants)[train_index]\n",
    "        test_participant = np.unique(participants)[test_index][0]\n",
    "\n",
    "        # 참여자별 데이터 분리\n",
    "        train_mask = np.isin(participants, train_participants)\n",
    "        test_mask = participants == test_participant\n",
    "\n",
    "        X_train, X_test = X[train_mask], X[test_mask]\n",
    "        y_train, y_test = y_categorical[train_mask], y_categorical[test_mask]\n",
    "\n",
    "        # 모델 생성 및 학습\n",
    "        model = create_cnn_model(input_shape, num_classes)\n",
    "        #batch_size = get_batch_size()\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "        # 학습 과정 확인\n",
    "        print(\"Training history:\")\n",
    "        print(\"Accuracy:\", history.history['accuracy'])\n",
    "        print(\"Loss:\", history.history['loss'])\n",
    "\n",
    "        # 모델 평가\n",
    "        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        print(f\"Test participant: {test_participant}, Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "        # 테스트 데이터 예측\n",
    "        for i, test_sample in enumerate(X_test):\n",
    "            test_sample_expanded = np.expand_dims(test_sample, axis=0)  # 배치 차원 추가\n",
    "            prediction = model.predict(test_sample_expanded)\n",
    "            predicted_class = np.argmax(prediction, axis=1)[0]  # 예측된 클래스\n",
    "            true_class = np.argmax(y_test[i])  # 실제 클래스\n",
    "            print(f\"Sample {i}: Prediction (0=negative, 1=positive): {predicted_class}, True: {true_class}\")\n",
    "\n",
    "    print(f\"Mean accuracy across participants: {np.mean(accuracy_scores):.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predict_test_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b086a-4965-4988-8bf4-c7a2f5af5d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed396b-3f76-41e9-bcf0-99bcd4fc7e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
