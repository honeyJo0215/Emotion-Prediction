{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "985baed9-9afe-46ff-9e32-1475ee231f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# TensorFlow 로그 레벨 설정\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Failed to set memory growth: {e}\")\n",
    "else:\n",
    "    print(\"No GPU devices found. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb46b3fe-5c78-416d-bf4b-c39fd861f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    \"\"\"\n",
    "    데이터를 로드하고, 레이블과 파일 이름을 포함하여 반환하는 함수\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): 데이터가 저장된 디렉토리 경로\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): 입력 데이터\n",
    "        y (np.ndarray): 레이블\n",
    "        participants (np.ndarray): 참여자 정보\n",
    "        file_names (np.ndarray): 각 샘플의 파일 이름\n",
    "    \"\"\"\n",
    "    # Positive(긍정)과 Negative(부정) 데이터를 저장할 리스트 초기화\n",
    "    files_positive = []\n",
    "    files_negative = []\n",
    "\n",
    "    # 디렉토리에 있는 파일들을 탐색\n",
    "    for file in os.listdir(directory):\n",
    "        # 파일 이름에 '_positive_'가 포함되어 있으면 positive 파일 리스트에 추가\n",
    "        if '_positive_' in file:\n",
    "            files_positive.append(os.path.join(directory, file))\n",
    "        # 파일 이름에 '_negative_'가 포함되어 있으면 negative 파일 리스트에 추가\n",
    "        elif '_negative_' in file:\n",
    "            files_negative.append(os.path.join(directory, file))\n",
    "\n",
    "    # positive 또는 negative 파일이 하나도 없을 경우 예외를 발생시킴\n",
    "    if not files_positive or not files_negative:\n",
    "        raise ValueError(f\"No files found. Positive: {files_positive}, Negative: {files_negative}\")\n",
    "\n",
    "    # positive와 negative 파일의 데이터를 읽어서 각각 리스트에 저장\n",
    "    positive_data = [np.load(file) for file in files_positive]  # positive 파일 데이터 로드\n",
    "    negative_data = [np.load(file) for file in files_negative]  # negative 파일 데이터 로드\n",
    "\n",
    "    # positive와 negative 데이터를 합쳐서 X 데이터로 생성\n",
    "    # axis=0은 데이터를 샘플 축(행)으로 결합함\n",
    "    X = np.concatenate(positive_data + negative_data, axis=0)\n",
    "\n",
    "    # y 레이블 생성\n",
    "    # positive 데이터의 개수만큼 1로 된 레이블 생성 후\n",
    "    # negative 데이터의 개수만큼 0으로 된 레이블을 추가\n",
    "    y = np.array([1] * len(np.concatenate(positive_data)) + [0] * len(np.concatenate(negative_data)))\n",
    "\n",
    "    # 참여자 정보(participants) 및 파일 이름(file_names) 생성\n",
    "    participants = []\n",
    "    file_names = []\n",
    "    for file in files_positive + files_negative:\n",
    "        # 파일 이름에서 참여자 ID 추출 (파일 이름 예: \"001_positive_data.npy\")\n",
    "        participant_id = os.path.basename(file).split('_')[0]\n",
    "        data = np.load(file)\n",
    "        num_samples = data.shape[0]\n",
    "        participants.extend([participant_id] * num_samples)\n",
    "        file_names.extend([os.path.basename(file)] * num_samples)\n",
    "\n",
    "    # 리스트를 NumPy 배열로 변환\n",
    "    participants = np.array(participants)\n",
    "    file_names = np.array(file_names)\n",
    "\n",
    "    # 최종적으로 데이터(X), 레이블(y), 참여자 정보(participants), 파일 이름(file_names)를 반환\n",
    "    return X, y, participants, file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9735ed5-dbb8-434b-af82-e04a7d730e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, num_classes, save_path):\n",
    "    \"\"\"\n",
    "    CNN 모델을 생성, 컴파일하고 .h5 파일로 저장하는 함수\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터의 형태 (예: (timesteps, features))\n",
    "        num_classes (int): 출력 클래스의 수 (예: 감정 레이블의 개수)\n",
    "        save_path (str): 생성된 모델을 저장할 .h5 파일 경로\n",
    "\n",
    "    Returns:\n",
    "        model (Sequential): 생성된 CNN 모델\n",
    "    \"\"\"\n",
    "    # Sequential 모델 생성\n",
    "    model = Sequential([\n",
    "        # 1D Convolutional Layer: 32개의 필터, kernel_size=3, 활성화 함수 ReLU\n",
    "        # input_shape 지정 (첫 번째 레이어에서만 필요)\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "\n",
    "        # MaxPooling Layer: 풀링 크기(pool_size)=2, strides=1\n",
    "        MaxPooling1D(pool_size=2, strides=1),\n",
    "\n",
    "        # 1D Convolutional Layer: 64개의 필터, kernel_size=3, 활성화 함수 ReLU\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "\n",
    "        # MaxPooling Layer: 풀링 크기(pool_size)=2, strides=1\n",
    "        MaxPooling1D(pool_size=2, strides=1),\n",
    "\n",
    "        # Flatten Layer: 1D 데이터를 1차원으로 펼침\n",
    "        Flatten(),\n",
    "\n",
    "        # Fully Connected Layer: 128개의 뉴런, 활성화 함수 ReLU\n",
    "        Dense(128, activation='relu'),\n",
    "\n",
    "        # Dropout Layer: 50%의 뉴런을 무작위로 비활성화 (overfitting 방지)\n",
    "        Dropout(0.5),\n",
    "\n",
    "        # Output Layer: 클래스 수에 따라 Softmax 활성화 함수 사용\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일: 최적화 알고리즘, 손실 함수, 평가지표 설정\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 모델 저장\n",
    "    model.save(save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "    return model  # 생성된 모델 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5b2b945-2e66-4bd0-9090-91ec9f3ddc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 평가 함수\n",
    "def evaluate_saved_model(data_directory, model_save_path):\n",
    "    # 데이터 디렉토리에서 테스트 데이터 로드\n",
    "    print(\"Loading test data...\")\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for file_name in os.listdir(data_directory):\n",
    "        if file_name.endswith(\".npy\"):\n",
    "            data_path = os.path.join(data_directory, file_name)\n",
    "            data = np.load(data_path, allow_pickle=True)  # allow_pickle=True로 수정\n",
    "\n",
    "            label = 1 if \"positive\" in file_name else 0\n",
    "            X_test.append(data)\n",
    "            y_test.append(label)\n",
    "\n",
    "    # 데이터 리스트를 동일한 길이로 패딩\n",
    "    max_channels = max(data.shape[0] if data.ndim > 2 else 1 for data in X_test)\n",
    "    max_timesteps = max(data.shape[-1] if data.ndim > 1 else len(data) for data in X_test)\n",
    "\n",
    "    X_test_padded = []\n",
    "\n",
    "    for data in X_test:\n",
    "        if data.ndim == 3:\n",
    "            padded_data = np.pad(data, ((0, max_channels - data.shape[0]), (0, 0), (0, max_timesteps - data.shape[-1])), mode='constant')\n",
    "        elif data.ndim == 2:\n",
    "            padded_data = np.pad(data, ((0, max_channels - data.shape[0]), (0, max_timesteps - data.shape[-1])), mode='constant')\n",
    "        else:\n",
    "            padded_data = np.pad(data, (0, max_timesteps - len(data)), mode='constant')\n",
    "        X_test_padded.append(padded_data)\n",
    "\n",
    "    # numpy 배열로 변환\n",
    "    X_test = np.array(X_test_padded)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    print(\"Original X_test shape:\", X_test.shape)\n",
    "\n",
    "    # 데이터 재구성\n",
    "    try:\n",
    "        target_timesteps = 100  # 모델에서 요구하는 타임스텝 크기\n",
    "        target_features = 64  # 모델에서 요구하는 피처 크기\n",
    "\n",
    "        reshaped_X_test = X_test.reshape(X_test.shape[0], target_timesteps, target_features)\n",
    "        reshaped_y_test = np.repeat(y_test, reshaped_X_test.shape[0] // y_test.shape[0])\n",
    "\n",
    "        print(\"Reshaped X_test shape:\", reshaped_X_test.shape)\n",
    "        print(\"Reshaped y_test shape:\", reshaped_y_test.shape)\n",
    "    except ValueError as e:\n",
    "        print(f\"Reshape Error: {e}\")\n",
    "        return\n",
    "\n",
    "    # 저장된 모델 로드\n",
    "    print(\"Loading model from:\", model_save_path)\n",
    "    model = load_model(model_save_path)\n",
    "\n",
    "    # 모델 평가\n",
    "    print(\"Evaluating the model...\")\n",
    "    loss, accuracy = model.evaluate(reshaped_X_test, reshaped_y_test, verbose=1)\n",
    "    print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "    # 모델 예측\n",
    "    predictions = model.predict(reshaped_X_test)\n",
    "    predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "    for i, (actual, predicted) in enumerate(zip(reshaped_y_test, predicted_classes)):\n",
    "        print(f\"Sample {i}: Actual: {actual}, Predicted: {predicted[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e130a0e-8bcd-45ee-adfc-3e7f371ef006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and saving the model...\n",
      "Model saved to cnn_intra_model.h5\n",
      "\n",
      "Evaluating the saved model...\n",
      "Loading test data...\n",
      "Original X_test shape: (20, 22, 8, 5120)\n",
      "Reshaped X_test shape: (160, 22, 1, 5120)\n",
      "Reshaped y_test shape: (160,)\n",
      "Loading model from: cnn_intra_model.h5\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32, 22, 1, 5120), dtype=float32). Expected shape (None, 100, 64), but input has incompatible shape (32, 22, 1, 5120)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 22, 1, 5120), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     evaluate_saved_model(data_directory,model_save_path)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 17\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 저장된 모델 평가\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating the saved model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mevaluate_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 59\u001b[0m, in \u001b[0;36mevaluate_saved_model\u001b[0;34m(data_directory, model_save_path)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# 모델 평가\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreshaped_X_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreshaped_y_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# 모델 예측\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/mycondaenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda/envs/mycondaenv/lib/python3.12/site-packages/keras/src/models/functional.py:273\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    272\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     )\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32, 22, 1, 5120), dtype=float32). Expected shape (None, 100, 64), but input has incompatible shape (32, 22, 1, 5120)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 22, 1, 5120), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    메인 함수: CNN 모델 생성, 저장 및 평가 실행\n",
    "    \"\"\"\n",
    "    # 데이터 디렉토리 및 모델 저장 경로 설정\n",
    "    data_directory = '/home/bcml1/2025_EMOTION/DEAP_EEG/ch_BPF'  # 데이터를 저장한 디렉토리 경로\n",
    "    model_save_path = 'cnn_intra_model.h5'  # 모델 저장 경로\n",
    "\n",
    "    # 모델 생성 및 저장\n",
    "    print(\"Creating and saving the model...\")\n",
    "    input_shape = (100, 64)  # 예시 입력 데이터 형태 (timesteps, features)\n",
    "    num_classes = 2  # 예시 클래스 개수\n",
    "    create_cnn_model(input_shape, num_classes, model_save_path)\n",
    "\n",
    "    # 저장된 모델 평가\n",
    "    print(\"\\nEvaluating the saved model...\")\n",
    "    evaluate_saved_model(data_directory,model_save_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459fc98-587d-463a-9271-430b84a88688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
