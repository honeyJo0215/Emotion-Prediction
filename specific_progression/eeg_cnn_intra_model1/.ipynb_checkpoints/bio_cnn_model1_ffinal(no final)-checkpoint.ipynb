{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d5c53b-fbe6-468c-8a97-bf99add287b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 16:16:51.720001: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-29 16:17:04.463034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-12-29 16:17:29.459874: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-29 16:17:30.999741: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-29 16:17:31.002576: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# TensorFlow 로그 레벨 설정\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Failed to set memory growth: {e}\")\n",
    "else:\n",
    "    print(\"No GPU devices found. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417b7856-d7d6-4ddd-8db7-3baab8c1955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    \"\"\"\n",
    "    데이터를 로드하고, 레이블과 파일 이름을 포함하여 반환하는 함수\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): 데이터가 저장된 디렉토리 경로\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): 입력 데이터\n",
    "        y (np.ndarray): 레이블\n",
    "        participants (np.ndarray): 참여자 정보\n",
    "        file_names (np.ndarray): 각 샘플의 파일 이름\n",
    "    \"\"\"\n",
    "    # Positive(긍정)과 Negative(부정) 데이터를 저장할 리스트 초기화\n",
    "    files_positive = []\n",
    "    files_negative = []\n",
    "\n",
    "    # 디렉토리에 있는 파일들을 탐색\n",
    "    for file in os.listdir(directory):\n",
    "        # 파일 이름에 '_positive_'가 포함되어 있으면 positive 파일 리스트에 추가\n",
    "        if '_positive_' in file:\n",
    "            files_positive.append(os.path.join(directory, file))\n",
    "        # 파일 이름에 '_negative_'가 포함되어 있으면 negative 파일 리스트에 추가\n",
    "        elif '_negative_' in file:\n",
    "            files_negative.append(os.path.join(directory, file))\n",
    "\n",
    "    # positive 또는 negative 파일이 하나도 없을 경우 예외를 발생시킴\n",
    "    if not files_positive or not files_negative:\n",
    "        raise ValueError(f\"No files found. Positive: {files_positive}, Negative: {files_negative}\")\n",
    "\n",
    "    # positive와 negative 파일의 데이터를 읽어서 각각 리스트에 저장\n",
    "    positive_data = [np.load(file) for file in files_positive]  # positive 파일 데이터 로드\n",
    "    negative_data = [np.load(file) for file in files_negative]  # negative 파일 데이터 로드\n",
    "\n",
    "    # positive와 negative 데이터를 합쳐서 X 데이터로 생성\n",
    "    # axis=0은 데이터를 샘플 축(행)으로 결합함\n",
    "    X = np.concatenate(positive_data + negative_data, axis=0)\n",
    "\n",
    "    # y 레이블 생성\n",
    "    # positive 데이터의 개수만큼 1로 된 레이블 생성 후\n",
    "    # negative 데이터의 개수만큼 0으로 된 레이블을 추가\n",
    "    y = np.array([1] * len(np.concatenate(positive_data)) + [0] * len(np.concatenate(negative_data)))\n",
    "\n",
    "    # 참여자 정보(participants) 및 파일 이름(file_names) 생성\n",
    "    participants = []\n",
    "    file_names = []\n",
    "    for file in files_positive + files_negative:\n",
    "        # 파일 이름에서 참여자 ID 추출 (파일 이름 예: \"001_positive_data.npy\")\n",
    "        participant_id = os.path.basename(file).split('_')[0]\n",
    "        data = np.load(file)\n",
    "        num_samples = data.shape[0]\n",
    "        participants.extend([participant_id] * num_samples)\n",
    "        file_names.extend([os.path.basename(file)] * num_samples)\n",
    "\n",
    "    # 리스트를 NumPy 배열로 변환\n",
    "    participants = np.array(participants)\n",
    "    file_names = np.array(file_names)\n",
    "\n",
    "    # 최종적으로 데이터(X), 레이블(y), 참여자 정보(participants), 파일 이름(file_names)를 반환\n",
    "    return X, y, participants, file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2822f993-0d67-4887-8837-d3e571ea6c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    CNN 모델을 생성하고 컴파일하는 함수\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터의 형태 (예: (timesteps, features))\n",
    "        num_classes (int): 출력 클래스의 수 (예: 감정 레이블의 개수)\n",
    "\n",
    "    Returns:\n",
    "        model (Sequential): 생성된 CNN 모델\n",
    "    \"\"\"\n",
    "    # Sequential 모델 생성\n",
    "    model = Sequential([\n",
    "        # 1D Convolutional Layer: 32개의 필터, kernel_size=3, 활성화 함수 ReLU\n",
    "        # input_shape 지정 (첫 번째 레이어에서만 필요)\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "\n",
    "        # MaxPooling Layer: 풀링 크기(pool_size)=2, strides=1\n",
    "        MaxPooling1D(pool_size=2, strides=1),\n",
    "\n",
    "        # 1D Convolutional Layer: 64개의 필터, kernel_size=3, 활성화 함수 ReLU\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "\n",
    "        # MaxPooling Layer: 풀링 크기(pool_size)=2, strides=1\n",
    "        MaxPooling1D(pool_size=2, strides=1),\n",
    "\n",
    "        # Flatten Layer: 1D 데이터를 1차원으로 펼침\n",
    "        Flatten(),\n",
    "\n",
    "        # Fully Connected Layer: 128개의 뉴런, 활성화 함수 ReLU\n",
    "        Dense(128, activation='relu'),\n",
    "\n",
    "        # Dropout Layer: 50%의 뉴런을 무작위로 비활성화 (overfitting 방지)\n",
    "        Dropout(0.5),\n",
    "\n",
    "        # Output Layer: 클래스 수에 따라 Softmax 활성화 함수 사용\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일: 최적화 알고리즘, 손실 함수, 평가지표 설정\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model  # 생성된 모델 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5082a4e-f7c3-4b9c-a42b-95d423664c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(directory, save_path):\n",
    "    \"\"\"\n",
    "    데이터를 로드하고 CNN 모델을 학습한 후 저장하는 함수\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): 데이터가 저장된 디렉토리 경로\n",
    "        save_path (str): 학습된 모델을 저장할 .h5 파일 경로\n",
    "    \"\"\"\n",
    "    X, y, participants, _ = load_data(directory)\n",
    "    num_classes = len(np.unique(y))\n",
    "    input_shape = X.shape[1:]\n",
    "\n",
    "    y_categorical = to_categorical(y, num_classes=num_classes)\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    for train_index, test_index in logo.split(X, y_categorical, groups=participants):\n",
    "        print(f\"Training on fold with {len(train_index)} samples...\")\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y_categorical[train_index], y_categorical[test_index]\n",
    "\n",
    "        model = create_cnn_model(input_shape, num_classes)\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "        # 모델 저장\n",
    "        model.save(save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "\n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Test session accuracy: {test_accuracy:.4f}\")\n",
    "        break  # LOGO 검증에서 첫 번째 세션만 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e775137-349a-4cb6-929e-29679f9a6ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 예측 및 결과 저장 함수\n",
    "def predict_test_samples():\n",
    "    \"\"\"\n",
    "    모델을 학습하고 평가한 후, 결과를 텍스트 파일로 저장하는 함수\n",
    "    \"\"\"\n",
    "    directory = '/home/bcml1/2025_EMOTION/DEAP_EEG/ch_BPF'  # 데이터를 저장한 디렉토리 경로\n",
    "    # directory = '/home/bcml1/sigenv/eeg_cnn_model1'  # 데이터를 저장한 디렉토리 경로 (주석 처리됨)\n",
    "    \n",
    "    X, y, participants, file_names = load_data(directory)\n",
    "\n",
    "    # 데이터 크기 확인\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}, participants shape: {participants.shape}, file_names shape: {file_names.shape}\")\n",
    "\n",
    "    # participants 배열의 크기가 X와 y의 첫 번째 축과 일치하지 않는 경우 처리\n",
    "    if participants.shape[0] != X.shape[0] or participants.shape[0] != y.shape[0] or file_names.shape[0] != X.shape[0]:\n",
    "        raise ValueError(\"Mismatch in dimensions: 'participants', 'X', 'y', and 'file_names' must have the same number of samples.\")\n",
    "\n",
    "    # 문자열 레이블을 숫자형 레이블로 매핑\n",
    "    unique_labels = np.unique(y)\n",
    "    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    y_int = np.array([label_to_int[label] for label in y])\n",
    "\n",
    "    num_classes = len(unique_labels)\n",
    "    input_shape = X.shape[1:]  # 데이터가 올바르게 reshape되었다고 가정\n",
    "    y_categorical = to_categorical(y_int, num_classes=num_classes)\n",
    "\n",
    "    # Leave-One-Group-Out 방식으로 intra-session 검증\n",
    "    logo = LeaveOneGroupOut()\n",
    "    accuracy_scores = []\n",
    "\n",
    "    # 전체 예측 결과 저장을 위한 리스트 초기화\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    all_file_names = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(logo.split(X, y_categorical, groups=participants), 1):\n",
    "        print(f\"\\nFold {fold}:\")\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y_categorical[train_index], y_categorical[test_index]\n",
    "        file_names_test = file_names[test_index]\n",
    "\n",
    "        # 모델 생성 및 학습\n",
    "        model = create_cnn_model(input_shape, num_classes)\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)  # verbose=0으로 변경하여 출력 최소화\n",
    "\n",
    "        # 학습 과정 확인\n",
    "        print(\"Training history:\")\n",
    "        print(\"Accuracy:\", history.history['accuracy'])\n",
    "        print(\"Loss:\", history.history['loss'])\n",
    "\n",
    "        # 모델 예측\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "        # 정확도 계산\n",
    "        test_accuracy = accuracy_score(y_true, y_pred)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        print(f\"Test session accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "        # 전체 예측 결과 저장\n",
    "        all_true.extend(y_true)\n",
    "        all_pred.extend(y_pred)\n",
    "        all_file_names.extend(file_names_test)\n",
    "\n",
    "    # 전체 정확도 및 분류 보고서 계산\n",
    "    final_accuracy = accuracy_score(all_true, all_pred)\n",
    "    classification_rep = classification_report(all_true, all_pred, target_names=['negative', 'positive'], digits=4)\n",
    "\n",
    "    # 파일 수준의 예측 상세 정보 생성\n",
    "    prediction_details = []\n",
    "    for file, true, pred in zip(all_file_names, all_true, all_pred):\n",
    "        correctness = \"Correct\" if true == pred else \"Incorrect\"\n",
    "        prediction_details.append(f\"{file}: Predicted={pred}, Actual={true} ({correctness})\")\n",
    "\n",
    "    # 결과를 텍스트 파일로 저장\n",
    "    output_file = \"cnn_model_intra_evaluation_results(test3)\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"Multimodal Model Evaluation Results\\n\")\n",
    "        f.write(f\"Final Accuracy: {final_accuracy:.4f}\\n\\n\")\n",
    "\n",
    "        f.write(\"Detailed Classification Report (Final):\\n\")\n",
    "        f.write(classification_rep + \"\\n\")\n",
    "\n",
    "        f.write(\"Prediction Details (file-level):\\n\")\n",
    "        for detail in prediction_details:\n",
    "            f.write(detail + \"\\n\")\n",
    "\n",
    "    print(f\"\\nEvaluation results have been saved to '{output_file}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5543e4f-a177-422d-8e78-5cc8bc55e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold with 283 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcml1/sigenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-12-29 16:17:34.435429: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-29 16:17:34.438280: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-29 16:17:34.440773: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-29 16:17:35.570183: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-29 16:17:35.573262: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-29 16:17:35.576510: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-29 16:17:35.578711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16313 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735489066.079321 2569225 service.cc:145] XLA service 0x7f97002459f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735489066.079368 2569225 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-12-29 16:17:47.496127: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-29 16:17:51.422561: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1735489077.145930 2569225 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 460ms/step - accuracy: 0.5645 - loss: 1180.6381\n",
      "Epoch 2/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5349 - loss: 1365.8516 \n",
      "Epoch 3/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5381 - loss: 1546.0254 \n",
      "Epoch 4/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5096 - loss: 1276.8218 \n",
      "Epoch 5/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4800 - loss: 958.0657 \n",
      "Epoch 6/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5617 - loss: 1066.8936\n",
      "Epoch 7/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5467 - loss: 1079.6423 \n",
      "Epoch 8/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6232 - loss: 729.1190 \n",
      "Epoch 9/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5058 - loss: 784.3708  \n",
      "Epoch 10/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5869 - loss: 706.2467  \n",
      "Epoch 11/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5609 - loss: 388.2442 \n",
      "Epoch 12/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5497 - loss: 343.4091 \n",
      "Epoch 13/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6207 - loss: 258.1420 \n",
      "Epoch 14/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6171 - loss: 438.4439 \n",
      "Epoch 15/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6030 - loss: 314.7323 \n",
      "Epoch 16/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6466 - loss: 147.3180 \n",
      "Epoch 17/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6186 - loss: 330.9005 \n",
      "Epoch 18/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6134 - loss: 71.7846 \n",
      "Epoch 19/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6449 - loss: 120.6332 \n",
      "Epoch 20/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6641 - loss: 152.8381 \n",
      "Epoch 21/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5958 - loss: 170.3396\n",
      "Epoch 22/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6646 - loss: 176.9652\n",
      "Epoch 23/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6576 - loss: 160.8552 \n",
      "Epoch 24/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6861 - loss: 57.5544 \n",
      "Epoch 25/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6813 - loss: 55.3287 \n",
      "Epoch 26/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7194 - loss: 85.2914 \n",
      "Epoch 27/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6460 - loss: 87.4770  \n",
      "Epoch 28/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6820 - loss: 33.8831 \n",
      "Epoch 29/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6725 - loss: 24.4834 \n",
      "Epoch 30/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6263 - loss: 34.3472 \n",
      "Epoch 31/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6720 - loss: 39.2246 \n",
      "Epoch 32/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6946 - loss: 18.6632\n",
      "Epoch 33/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6627 - loss: 19.3244\n",
      "Epoch 34/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6492 - loss: 12.7075\n",
      "Epoch 35/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7024 - loss: 12.6955\n",
      "Epoch 36/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7153 - loss: 7.2525 \n",
      "Epoch 37/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6806 - loss: 8.6301 \n",
      "Epoch 38/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7492 - loss: 13.8998 \n",
      "Epoch 39/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6936 - loss: 14.4146\n",
      "Epoch 40/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6153 - loss: 47.9582 \n",
      "Epoch 41/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6497 - loss: 10.0186\n",
      "Epoch 42/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7194 - loss: 13.4608\n",
      "Epoch 43/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7433 - loss: 22.9071 \n",
      "Epoch 44/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6900 - loss: 4.5684 \n",
      "Epoch 45/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6746 - loss: 5.9727 \n",
      "Epoch 46/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6808 - loss: 25.4582\n",
      "Epoch 47/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6665 - loss: 14.8951 \n",
      "Epoch 48/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6194 - loss: 7.7311 \n",
      "Epoch 49/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7320 - loss: 5.9605 \n",
      "Epoch 50/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7032 - loss: 3.5645 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to cnn_intra_model.h5\n",
      "Test session accuracy: 0.5641\n",
      "X shape: (322, 8, 5120), y shape: (322,), participants shape: (322,), file_names shape: (322,)\n",
      "\n",
      "Fold 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcml1/sigenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history:\n",
      "Accuracy: [0.4911660850048065, 0.5583038926124573, 0.5194346308708191, 0.5971731543540955, 0.5759717226028442, 0.5512367486953735, 0.5300353169441223, 0.6113074421882629, 0.5901060104370117, 0.5194346308708191, 0.6148409843444824, 0.537102460861206, 0.565371036529541, 0.6007066965103149, 0.6360424160957336, 0.6113074421882629, 0.685512363910675, 0.6325088143348694, 0.6113074421882629, 0.6183745861053467, 0.6431095600128174, 0.6325088143348694, 0.554770290851593, 0.6325088143348694, 0.6572437882423401, 0.6819788217544556, 0.6466431021690369, 0.6643109321594238, 0.7102473378181458, 0.6501767039299011, 0.6678445339202881, 0.6678445339202881, 0.6431095600128174, 0.6749116778373718, 0.6537102460861206, 0.6537102460861206, 0.6819788217544556, 0.6466431021690369, 0.6925795078277588, 0.6713780760765076, 0.6431095600128174, 0.6219081282615662, 0.6007066965103149, 0.6572437882423401, 0.6254416704177856, 0.565371036529541, 0.5971731543540955, 0.5512367486953735, 0.6183745861053467, 0.5689045786857605]\n",
      "Loss: [2544.501953125, 3100.324951171875, 1876.4390869140625, 910.8931274414062, 1754.887939453125, 1488.5196533203125, 975.32861328125, 684.4671020507812, 564.1007690429688, 1397.801513671875, 408.4368896484375, 1076.501708984375, 885.0855712890625, 480.3539733886719, 281.52032470703125, 418.1780090332031, 165.58644104003906, 192.8235626220703, 336.78314208984375, 291.62774658203125, 259.5987243652344, 237.14344787597656, 234.86456298828125, 285.158935546875, 216.2207794189453, 152.77589416503906, 120.86172485351562, 74.23368072509766, 78.5250473022461, 59.81599807739258, 25.224225997924805, 66.0518569946289, 109.15998077392578, 51.54792785644531, 60.35185241699219, 37.07563781738281, 23.559215545654297, 46.211063385009766, 35.92323303222656, 115.47189331054688, 32.34235382080078, 13.887256622314453, 37.53179931640625, 5.9716386795043945, 7.868612766265869, 27.24823760986328, 39.12919998168945, 14.902362823486328, 44.602108001708984, 19.305456161499023]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278ms/step\n",
      "Test session accuracy: 0.6410\n",
      "\n",
      "Fold 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcml1/sigenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history:\n",
      "Accuracy: [0.5034482479095459, 0.5758620500564575, 0.5413793325424194, 0.5275862216949463, 0.5310344696044922, 0.5724138021469116, 0.6068965792655945, 0.5758620500564575, 0.6034482717514038, 0.5344827771186829, 0.5103448033332825, 0.5931034684181213, 0.6000000238418579, 0.5862069129943848, 0.5551724433898926, 0.5931034684181213, 0.5827586054801941, 0.634482741355896, 0.6206896305084229, 0.6068965792655945, 0.6137930750846863, 0.617241382598877, 0.5931034684181213, 0.6000000238418579, 0.5620689392089844, 0.6103448271751404, 0.6275861859321594, 0.6241379380226135, 0.6137930750846863, 0.6068965792655945, 0.6275861859321594, 0.6620689630508423, 0.634482741355896, 0.6448276042938232, 0.6413792967796326, 0.6379310488700867, 0.6206896305084229, 0.5551724433898926, 0.5862069129943848, 0.5551724433898926, 0.5793103575706482, 0.6068965792655945, 0.5551724433898926, 0.5724138021469116, 0.5793103575706482, 0.5896551609039307, 0.6137930750846863, 0.5344827771186829, 0.5965517163276672, 0.5620689392089844]\n",
      "Loss: [4836.4248046875, 4375.15283203125, 4539.60400390625, 3422.46337890625, 3779.107421875, 2721.12890625, 3253.853271484375, 2495.911376953125, 2739.764892578125, 3531.1845703125, 2093.494873046875, 2422.470458984375, 1822.2099609375, 1345.332763671875, 1198.068603515625, 1377.07666015625, 2559.4775390625, 1534.2066650390625, 1318.955810546875, 1223.5760498046875, 1273.668701171875, 876.7713012695312, 1092.9559326171875, 705.0103149414062, 938.4618530273438, 1047.8956298828125, 539.2631225585938, 368.4039611816406, 580.35791015625, 356.7784729003906, 309.4183349609375, 257.34844970703125, 610.6398315429688, 354.43255615234375, 242.7255096435547, 318.8049011230469, 707.27734375, 1223.171630859375, 1057.0687255859375, 542.3109130859375, 519.9925537109375, 380.0483703613281, 297.7469787597656, 421.0782470703125, 258.1982727050781, 234.63771057128906, 166.01895141601562, 142.39413452148438, 184.7061767578125, 206.46742248535156]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
      "Test session accuracy: 0.5312\n",
      "\n",
      "Fold 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcml1/sigenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-12-29 16:18:35.799273: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng3{k11=2} for conv (f32[1,32,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,1,3]{3,2,1,0}, f32[32,64,1,3]{3,2,1,0}), window={size=1x3 pad=0_0x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-12-29 16:18:36.683305: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.884124211s\n",
      "Trying algorithm eng3{k11=2} for conv (f32[1,32,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,1,3]{3,2,1,0}, f32[32,64,1,3]{3,2,1,0}), window={size=1x3 pad=0_0x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-12-29 16:18:37.800851: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f32[1,32,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,1,3]{3,2,1,0}, f32[32,64,1,3]{3,2,1,0}), window={size=1x3 pad=0_0x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-12-29 16:18:38.493059: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.692281034s\n",
      "Trying algorithm eng4{} for conv (f32[1,32,1,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,1,3]{3,2,1,0}, f32[32,64,1,3]{3,2,1,0}), window={size=1x3 pad=0_0x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history:\n",
      "Accuracy: [0.512110710144043, 0.5224913358688354, 0.5224913358688354, 0.5397923588752747, 0.5813148617744446, 0.5674740672111511, 0.5328719615936279, 0.6089965105056763, 0.5640138387680054, 0.5951557159423828, 0.5847750902175903, 0.633217990398407, 0.6747404932975769, 0.6228373646736145, 0.6262975931167603, 0.5709342360496521, 0.5328719615936279, 0.529411792755127, 0.5259515643119812, 0.5916954874992371, 0.5467128157615662, 0.5951557159423828, 0.6089965105056763, 0.5813148617744446, 0.5916954874992371, 0.6055363416671753, 0.5882353186607361, 0.6020761132240295, 0.6262975931167603, 0.5951557159423828, 0.5570934414863586, 0.5536332130432129, 0.6159169673919678, 0.5847750902175903, 0.5951557159423828, 0.6297577619552612, 0.6089965105056763, 0.6228373646736145, 0.6228373646736145, 0.633217990398407, 0.5674740672111511, 0.5916954874992371, 0.5467128157615662, 0.6089965105056763, 0.5916954874992371, 0.5709342360496521, 0.5882353186607361, 0.5813148617744446, 0.5847750902175903, 0.5951557159423828]\n",
      "Loss: [2630.7236328125, 3810.671630859375, 2520.700439453125, 4212.88916015625, 2691.355224609375, 1549.66845703125, 942.5972290039062, 1521.9708251953125, 1715.5675048828125, 1273.8062744140625, 904.1070556640625, 548.1411743164062, 1221.3560791015625, 564.4428100585938, 438.7369384765625, 1193.7276611328125, 2221.8818359375, 1586.0633544921875, 1103.7452392578125, 978.17041015625, 457.6764221191406, 360.9819030761719, 785.8299560546875, 535.487060546875, 379.0523986816406, 269.5503234863281, 421.78570556640625, 235.6350860595703, 458.977294921875, 763.0289306640625, 629.3156127929688, 289.2896423339844, 218.37673950195312, 206.25360107421875, 201.2162322998047, 118.0277099609375, 100.43928527832031, 120.75129699707031, 256.81109619140625, 64.43610382080078, 263.7885437011719, 198.2965850830078, 281.2958068847656, 159.18724060058594, 289.1540222167969, 454.7349548339844, 204.07191467285156, 99.0997314453125, 83.76830291748047, 110.36964416503906]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f986dd1aca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f986dd1aca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299ms/step\n",
      "Test session accuracy: 0.6667\n",
      "\n",
      "Fold 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcml1/sigenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history:\n",
      "Accuracy: [0.5189003348350525, 0.5120275020599365, 0.5395188927650452, 0.5326460599899292, 0.5532646179199219, 0.6219931244850159, 0.5876288414001465, 0.5395188927650452, 0.5532646179199219, 0.5223367810249329, 0.6116838455200195, 0.5738831758499146, 0.6082473993301392, 0.6116838455200195, 0.6460481286048889, 0.6941580772399902, 0.6632302403450012, 0.6185566782951355, 0.6632302403450012, 0.6048110127449036, 0.5945017337799072, 0.6529209613800049, 0.6082473993301392, 0.6151202917098999, 0.6219931244850159, 0.5910652875900269, 0.5463917255401611, 0.6116838455200195, 0.5704467296600342, 0.5429553389549255, 0.5601374506950378, 0.5945017337799072, 0.5945017337799072, 0.6529209613800049, 0.6048110127449036, 0.5979381203651428, 0.6151202917098999, 0.5841924548149109, 0.5876288414001465, 0.5910652875900269, 0.6116838455200195, 0.5910652875900269, 0.6048110127449036, 0.6048110127449036, 0.5841924548149109, 0.5910652875900269, 0.5979381203651428, 0.6219931244850159, 0.5773195624351501, 0.6219931244850159]\n",
      "Loss: [4355.0791015625, 2960.07861328125, 4094.844970703125, 3263.483642578125, 1920.4476318359375, 1506.6578369140625, 1418.576904296875, 1677.4697265625, 2309.543701171875, 2415.2646484375, 1133.0819091796875, 1574.4061279296875, 666.45703125, 656.0481567382812, 447.1771240234375, 517.3668212890625, 802.6358032226562, 754.9926147460938, 526.1417236328125, 617.2507934570312, 1336.90478515625, 1866.8580322265625, 3573.208251953125, 627.9547119140625, 1647.996826171875, 4240.97705078125, 1664.7373046875, 867.1463012695312, 888.2152099609375, 923.2767333984375, 440.7875671386719, 319.259033203125, 257.2946472167969, 525.4939575195312, 250.24871826171875, 216.3162384033203, 162.97207641601562, 228.94859313964844, 46.92839431762695, 67.49164581298828, 37.29346466064453, 70.56001281738281, 40.96000289916992, 40.66056823730469, 21.092506408691406, 28.3168888092041, 15.750778198242188, 9.269031524658203, 21.64872169494629, 8.455222129821777]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f986da232e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f986da232e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786ms/step\n",
      "Test session accuracy: 0.5161\n",
      "\n",
      "Fold 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcml1/sigenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history:\n",
      "Accuracy: [0.5068492889404297, 0.5102739930152893, 0.517123281955719, 0.482876718044281, 0.5239726305007935, 0.5479452013969421, 0.5479452013969421, 0.5719178318977356, 0.5136986374855042, 0.6130136847496033, 0.585616409778595, 0.5924657583236694, 0.5650684833526611, 0.5753424763679504, 0.5924657583236694, 0.6438356041908264, 0.5445205569267273, 0.534246563911438, 0.6506849527359009, 0.6164383292198181, 0.5308219194412231, 0.6712328791618347, 0.5445205569267273, 0.5821917653083801, 0.6095890402793884, 0.6506849527359009, 0.6027397513389587, 0.6267123222351074, 0.6061643958091736, 0.5719178318977356, 0.5650684833526611, 0.5993150472640991, 0.5753424763679504, 0.5650684833526611, 0.5410959124565125, 0.5719178318977356, 0.568493127822876, 0.5582191944122314, 0.5650684833526611, 0.551369845867157, 0.6130136847496033, 0.5582191944122314, 0.6027397513389587, 0.5753424763679504, 0.5034246444702148, 0.5787671208381653, 0.5547945499420166, 0.5616438388824463, 0.5650684833526611, 0.5582191944122314]\n",
      "Loss: [3999.047607421875, 3032.655029296875, 3423.406005859375, 3908.147216796875, 3112.735107421875, 2665.412841796875, 1846.102783203125, 1662.20849609375, 1719.69580078125, 1216.3609619140625, 1081.726806640625, 974.023681640625, 685.4664306640625, 868.8274536132812, 630.8579711914062, 664.1981201171875, 1351.838623046875, 2562.652587890625, 1158.15234375, 703.8997802734375, 1063.821533203125, 608.3394775390625, 493.4919738769531, 430.49847412109375, 306.0220031738281, 292.71002197265625, 242.3975830078125, 233.0688934326172, 419.7067565917969, 372.2203674316406, 248.24996948242188, 182.6791229248047, 299.0755615234375, 121.55896759033203, 136.55653381347656, 65.08517456054688, 90.28392791748047, 155.989501953125, 96.56584930419922, 114.4143295288086, 81.41083526611328, 66.63436126708984, 14.872838020324707, 18.974952697753906, 18.621641159057617, 19.583053588867188, 9.648123741149902, 14.250210762023926, 13.691997528076172, 8.81554889678955]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901ms/step\n",
      "Test session accuracy: 0.5333\n",
      "\n",
      "Fold 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcml1/sigenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history:\n",
      "Accuracy: [0.5223367810249329, 0.5120275020599365, 0.4845360815525055, 0.5223367810249329, 0.5463917255401611, 0.5189003348350525, 0.5945017337799072, 0.5223367810249329, 0.5841924548149109, 0.5910652875900269, 0.5841924548149109, 0.6013745665550232, 0.5567010045051575, 0.5463917255401611, 0.5567010045051575, 0.5567010045051575, 0.5567010045051575, 0.5876288414001465, 0.5635738968849182, 0.5635738968849182, 0.5738831758499146, 0.5807560086250305, 0.5910652875900269, 0.5704467296600342, 0.6048110127449036, 0.6838487982749939, 0.5807560086250305, 0.5532646179199219, 0.5876288414001465, 0.6185566782951355, 0.5670102834701538, 0.6048110127449036, 0.5979381203651428, 0.5738831758499146, 0.6357388496398926, 0.6013745665550232, 0.5979381203651428, 0.6391752362251282, 0.6219931244850159, 0.5807560086250305, 0.5841924548149109, 0.6151202917098999, 0.6426116824150085, 0.5945017337799072, 0.5670102834701538, 0.5841924548149109, 0.6082473993301392, 0.6116838455200195, 0.6185566782951355, 0.5841924548149109]\n",
      "Loss: [3545.73193359375, 3904.706298828125, 2885.0634765625, 2321.0654296875, 1613.6282958984375, 2841.353515625, 2650.646728515625, 2202.147216796875, 1754.177001953125, 842.3720092773438, 2906.469970703125, 1026.5780029296875, 3087.375244140625, 2131.26513671875, 6899.09130859375, 2295.420654296875, 2797.895263671875, 1413.773193359375, 650.0609741210938, 1159.8594970703125, 1059.31298828125, 1152.6441650390625, 1040.2325439453125, 868.9717407226562, 586.6609497070312, 398.140625, 1205.648681640625, 389.98492431640625, 225.48611450195312, 286.2389221191406, 520.04931640625, 393.181640625, 500.4754638671875, 307.16168212890625, 662.7359619140625, 885.0149536132812, 398.38336181640625, 124.45567321777344, 369.7890930175781, 105.41351318359375, 81.12468719482422, 185.98597717285156, 186.07728576660156, 32.9405632019043, 71.70114135742188, 278.44830322265625, 212.53103637695312, 22.273855209350586, 124.8659896850586, 52.17464065551758]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n",
      "Test session accuracy: 0.6129\n",
      "\n",
      "Fold 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcml1/sigenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history:\n",
      "Accuracy: [0.5374149680137634, 0.5, 0.5646258592605591, 0.5544217824935913, 0.5714285969734192, 0.581632673740387, 0.5884353518486023, 0.5680271983146667, 0.5884353518486023, 0.6020408272743225, 0.6258503198623657, 0.5884353518486023, 0.6292517185211182, 0.704081654548645, 0.6836734414100647, 0.6836734414100647, 0.646258533000946, 0.6598639488220215, 0.6394557952880859, 0.6972789168357849, 0.7006802558898926, 0.7142857313156128, 0.7006802558898926, 0.6496598720550537, 0.6904761791229248, 0.6768707633018494, 0.7006802558898926, 0.6768707633018494, 0.6292517185211182, 0.6700680255889893, 0.6700680255889893, 0.6598639488220215, 0.6904761791229248, 0.6734693646430969, 0.6598639488220215, 0.6870748400688171, 0.6394557952880859, 0.6972789168357849, 0.7210884094238281, 0.704081654548645, 0.6258503198623657, 0.6190476417541504, 0.6360543966293335, 0.615646243095398, 0.6530612111091614, 0.6428571343421936, 0.6088435649871826, 0.6734693646430969, 0.646258533000946, 0.6734693646430969]\n",
      "Loss: [2678.584228515625, 2989.853271484375, 2216.32568359375, 2593.8017578125, 1152.0296630859375, 598.9685668945312, 1469.5357666015625, 1424.807373046875, 829.1024169921875, 799.991455078125, 617.375732421875, 636.6551513671875, 337.7629089355469, 262.8316955566406, 234.2638702392578, 267.1159973144531, 186.3893280029297, 147.69683837890625, 127.29444122314453, 155.623779296875, 206.23159790039062, 245.54501342773438, 301.50482177734375, 262.0255432128906, 431.03057861328125, 312.9248352050781, 133.2669219970703, 177.08761596679688, 404.96575927734375, 398.0941162109375, 305.94891357421875, 357.3272705078125, 267.3789367675781, 159.1576385498047, 175.44027709960938, 79.66136169433594, 108.78008270263672, 58.49494934082031, 64.97869873046875, 80.85779571533203, 89.61228942871094, 189.28895568847656, 70.23116302490234, 178.35989379882812, 72.58175659179688, 23.54591178894043, 56.14997863769531, 24.819446563720703, 29.87701988220215, 25.716814041137695]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830ms/step\n",
      "Test session accuracy: 0.5357\n",
      "\n",
      "Fold 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcml1/sigenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history:\n",
      "Accuracy: [0.46917808055877686, 0.5239726305007935, 0.5787671208381653, 0.5616438388824463, 0.5239726305007935, 0.5308219194412231, 0.5890411138534546, 0.585616409778595, 0.6130136847496033, 0.5719178318977356, 0.5582191944122314, 0.6027397513389587, 0.5582191944122314, 0.5890411138534546, 0.5787671208381653, 0.5616438388824463, 0.5753424763679504, 0.6198630332946777, 0.6404109597206116, 0.6369863152503967, 0.6164383292198181, 0.6404109597206116, 0.6232876777648926, 0.6164383292198181, 0.6609588861465454, 0.6849315166473389, 0.6575342416763306, 0.6506849527359009, 0.6506849527359009, 0.6849315166473389, 0.6130136847496033, 0.5821917653083801, 0.6164383292198181, 0.664383590221405, 0.6506849527359009, 0.6438356041908264, 0.6575342416763306, 0.6267123222351074, 0.6506849527359009, 0.6917808055877686, 0.6506849527359009, 0.681506872177124, 0.6952054500579834, 0.6678082346916199, 0.664383590221405, 0.6301369667053223, 0.6130136847496033, 0.6404109597206116, 0.6164383292198181, 0.6541095972061157]\n",
      "Loss: [3385.898681640625, 4304.7734375, 2614.592041015625, 2906.300048828125, 2799.396728515625, 2691.760986328125, 1741.052001953125, 1352.7174072265625, 2395.3154296875, 2132.845947265625, 1624.088134765625, 886.083740234375, 1205.9114990234375, 867.7591552734375, 661.1109619140625, 469.7576599121094, 347.0487060546875, 333.757080078125, 374.4996032714844, 208.92111206054688, 142.23239135742188, 560.3692626953125, 405.9263000488281, 170.64682006835938, 219.20957946777344, 199.72451782226562, 181.0611114501953, 118.81379699707031, 133.14947509765625, 234.0276336669922, 485.2229309082031, 397.8403625488281, 229.53451538085938, 120.6444091796875, 140.66720581054688, 82.00713348388672, 125.27796173095703, 58.065067291259766, 76.91024780273438, 75.12406158447266, 70.40106201171875, 104.19645690917969, 56.920692443847656, 68.84689331054688, 62.67043685913086, 49.398433685302734, 45.88985061645508, 38.89702606201172, 24.351715087890625, 35.60118103027344]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step\n",
      "Test session accuracy: 0.5667\n",
      "\n",
      "Fold 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcml1/sigenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history:\n",
      "Accuracy: [0.4982578456401825, 0.5540069937705994, 0.5470383167266846, 0.602787435054779, 0.5296167135238647, 0.5853658318519592, 0.5818815231323242, 0.588850200176239, 0.5574913024902344, 0.588850200176239, 0.592334508895874, 0.5818815231323242, 0.5783972144126892, 0.6062718033790588, 0.6550522446632385, 0.6620209217071533, 0.6271777153015137, 0.6898954510688782, 0.6898954510688782, 0.696864128112793, 0.6445993185043335, 0.6898954510688782, 0.6864111423492432, 0.6829268336296082, 0.6689895391464233, 0.6864111423492432, 0.7317073345184326, 0.700348436832428, 0.6898954510688782, 0.7735191583633423, 0.7421602606773376, 0.7804877758026123, 0.707317054271698, 0.7177700400352478, 0.7317073345184326, 0.693379819393158, 0.6585366129875183, 0.7177700400352478, 0.7526132464408875, 0.707317054271698, 0.6550522446632385, 0.6585366129875183, 0.6829268336296082, 0.6829268336296082, 0.6864111423492432, 0.7282230257987976, 0.7212543487548828, 0.6689895391464233, 0.7142857313156128, 0.6480836272239685]\n",
      "Loss: [4331.482421875, 2683.560546875, 2407.591064453125, 1911.2464599609375, 1732.189208984375, 1032.301025390625, 1514.2530517578125, 1965.2008056640625, 1344.510009765625, 1126.2406005859375, 1069.197021484375, 601.4542846679688, 650.3089599609375, 645.9637451171875, 641.3103637695312, 192.57077026367188, 479.6260986328125, 359.3016662597656, 183.05484008789062, 320.6942443847656, 291.6753845214844, 605.3694458007812, 249.1029510498047, 241.0745391845703, 311.56329345703125, 145.8435516357422, 199.0841522216797, 85.34163665771484, 112.94914245605469, 158.85243225097656, 185.48533630371094, 55.27632141113281, 97.68623352050781, 68.37458038330078, 147.65872192382812, 276.8157653808594, 77.04898834228516, 47.21615219116211, 126.19026184082031, 54.065338134765625, 81.15715789794922, 70.26168823242188, 19.953105926513672, 98.13200378417969, 118.94287872314453, 59.297760009765625, 242.4008026123047, 178.03530883789062, 93.56902313232422, 431.1126403808594]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410ms/step\n",
      "Test session accuracy: 0.5714\n",
      "\n",
      "Fold 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcml1/sigenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history:\n",
      "Accuracy: [0.4982698857784271, 0.5051903128623962, 0.5674740672111511, 0.5224913358688354, 0.5916954874992371, 0.5363321900367737, 0.5951557159423828, 0.5467128157615662, 0.5363321900367737, 0.5951557159423828, 0.5432525873184204, 0.6089965105056763, 0.5432525873184204, 0.5882353186607361, 0.5640138387680054, 0.5397923588752747, 0.5501729846000671, 0.6262975931167603, 0.5605536103248596, 0.5847750902175903, 0.5847750902175903, 0.5882353186607361, 0.633217990398407, 0.5674740672111511, 0.5916954874992371, 0.5813148617744446, 0.6089965105056763, 0.5743944644927979, 0.6401383876800537, 0.6366782188415527, 0.5951557159423828, 0.6193771362304688, 0.5709342360496521, 0.5743944644927979, 0.6020761132240295, 0.5986159443855286, 0.5709342360496521, 0.6055363416671753, 0.5951557159423828, 0.5605536103248596, 0.6228373646736145, 0.5951557159423828, 0.5674740672111511, 0.6297577619552612, 0.5916954874992371, 0.6297577619552612, 0.5501729846000671, 0.5709342360496521, 0.6228373646736145, 0.5916954874992371]\n",
      "Loss: [3158.33837890625, 2856.533203125, 3111.8134765625, 3091.057861328125, 3233.442138671875, 2113.488037109375, 2575.873291015625, 3404.304931640625, 4617.42578125, 1722.983154296875, 1888.59228515625, 1232.0731201171875, 1812.385986328125, 1959.138671875, 1562.973876953125, 1324.798828125, 1045.917724609375, 756.5232543945312, 770.482666015625, 511.3580627441406, 511.0433654785156, 444.07305908203125, 345.0336608886719, 1091.4150390625, 714.9405517578125, 523.0380859375, 770.5927124023438, 196.4095001220703, 919.0278930664062, 253.5410919189453, 234.92868041992188, 174.98023986816406, 223.66078186035156, 69.23856353759766, 588.2918090820312, 360.6395263671875, 366.6077880859375, 211.3049774169922, 110.13188934326172, 59.63701629638672, 70.43901824951172, 70.78379821777344, 54.242958068847656, 47.17216873168945, 111.54874420166016, 35.63962173461914, 21.5376033782959, 36.086490631103516, 28.110605239868164, 128.52915954589844]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step\n",
      "Test session accuracy: 0.4545\n",
      "\n",
      "Evaluation results have been saved to 'cnn_model_intra_evaluation_results(test3)'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_directory = \"/home/bcml1/2025_EMOTION/DEAP_EEG/ch_BPF\"  # 데이터 경로\n",
    "    model_save_path = \"cnn_intra_model.h5\"  # 모델 저장 경로\n",
    "    train_and_save_model(data_directory, model_save_path)\n",
    "    predict_test_samples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca28ba-db86-4fa2-bdee-133975138c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
