{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "985baed9-9afe-46ff-9e32-1475ee231f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# TensorFlow 로그 레벨 설정\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Failed to set memory growth: {e}\")\n",
    "else:\n",
    "    print(\"No GPU devices found. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb46b3fe-5c78-416d-bf4b-c39fd861f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    \"\"\"\n",
    "    데이터를 로드하고, 레이블과 파일 이름을 포함하여 반환하는 함수\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): 데이터가 저장된 디렉토리 경로\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): 입력 데이터\n",
    "        y (np.ndarray): 레이블\n",
    "        participants (np.ndarray): 참여자 정보\n",
    "        file_names (np.ndarray): 각 샘플의 파일 이름\n",
    "    \"\"\"\n",
    "    # Positive(긍정)과 Negative(부정) 데이터를 저장할 리스트 초기화\n",
    "    files_positive = []\n",
    "    files_negative = []\n",
    "\n",
    "    # 디렉토리에 있는 파일들을 탐색\n",
    "    for file in os.listdir(directory):\n",
    "        # 파일 이름에 '_positive_'가 포함되어 있으면 positive 파일 리스트에 추가\n",
    "        if '_positive_' in file:\n",
    "            files_positive.append(os.path.join(directory, file))\n",
    "        # 파일 이름에 '_negative_'가 포함되어 있으면 negative 파일 리스트에 추가\n",
    "        elif '_negative_' in file:\n",
    "            files_negative.append(os.path.join(directory, file))\n",
    "\n",
    "    # positive 또는 negative 파일이 하나도 없을 경우 예외를 발생시킴\n",
    "    if not files_positive or not files_negative:\n",
    "        raise ValueError(f\"No files found. Positive: {files_positive}, Negative: {files_negative}\")\n",
    "\n",
    "    # positive와 negative 파일의 데이터를 읽어서 각각 리스트에 저장\n",
    "    positive_data = [np.load(file) for file in files_positive]  # positive 파일 데이터 로드\n",
    "    negative_data = [np.load(file) for file in files_negative]  # negative 파일 데이터 로드\n",
    "\n",
    "    # positive와 negative 데이터를 합쳐서 X 데이터로 생성\n",
    "    # axis=0은 데이터를 샘플 축(행)으로 결합함\n",
    "    X = np.concatenate(positive_data + negative_data, axis=0)\n",
    "\n",
    "    # y 레이블 생성\n",
    "    # positive 데이터의 개수만큼 1로 된 레이블 생성 후\n",
    "    # negative 데이터의 개수만큼 0으로 된 레이블을 추가\n",
    "    y = np.array([1] * len(np.concatenate(positive_data)) + [0] * len(np.concatenate(negative_data)))\n",
    "\n",
    "    # 참여자 정보(participants) 및 파일 이름(file_names) 생성\n",
    "    participants = []\n",
    "    file_names = []\n",
    "    for file in files_positive + files_negative:\n",
    "        # 파일 이름에서 참여자 ID 추출 (파일 이름 예: \"001_positive_data.npy\")\n",
    "        participant_id = os.path.basename(file).split('_')[0]\n",
    "        data = np.load(file)\n",
    "        num_samples = data.shape[0]\n",
    "        participants.extend([participant_id] * num_samples)\n",
    "        file_names.extend([os.path.basename(file)] * num_samples)\n",
    "\n",
    "    # 리스트를 NumPy 배열로 변환\n",
    "    participants = np.array(participants)\n",
    "    file_names = np.array(file_names)\n",
    "\n",
    "    # 최종적으로 데이터(X), 레이블(y), 참여자 정보(participants), 파일 이름(file_names)를 반환\n",
    "    return X, y, participants, file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9735ed5-dbb8-434b-af82-e04a7d730e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    CNN 모델을 생성하고 컴파일하는 함수\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터의 형태 (예: (timesteps, features))\n",
    "        num_classes (int): 출력 클래스의 수 (예: 감정 레이블의 개수)\n",
    "\n",
    "    Returns:\n",
    "        model (Sequential): 생성된 CNN 모델\n",
    "    \"\"\"\n",
    "    # Sequential 모델 생성\n",
    "    model = Sequential([\n",
    "        # 1D Convolutional Layer: 32개의 필터, kernel_size=3, 활성화 함수 ReLU\n",
    "        # input_shape 지정 (첫 번째 레이어에서만 필요)\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "\n",
    "        # MaxPooling Layer: 풀링 크기(pool_size)=2, strides=1\n",
    "        MaxPooling1D(pool_size=2, strides=1),\n",
    "\n",
    "        # 1D Convolutional Layer: 64개의 필터, kernel_size=3, 활성화 함수 ReLU\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "\n",
    "        # MaxPooling Layer: 풀링 크기(pool_size)=2, strides=1\n",
    "        MaxPooling1D(pool_size=2, strides=1),\n",
    "\n",
    "        # Flatten Layer: 1D 데이터를 1차원으로 펼침\n",
    "        Flatten(),\n",
    "\n",
    "        # Fully Connected Layer: 128개의 뉴런, 활성화 함수 ReLU\n",
    "        Dense(128, activation='relu'),\n",
    "\n",
    "        # Dropout Layer: 50%의 뉴런을 무작위로 비활성화 (overfitting 방지)\n",
    "        Dropout(0.5),\n",
    "\n",
    "        # Output Layer: 클래스 수에 따라 Softmax 활성화 함수 사용\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일: 최적화 알고리즘, 손실 함수, 평가지표 설정\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model  # 생성된 모델 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5b2b945-2e66-4bd0-9090-91ec9f3ddc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load and evaluate saved model\n",
    "def evaluate_model(X, y, participants, model_path):\n",
    "    \"\"\"\n",
    "    Load a saved model and evaluate it on the test data.\n",
    "\n",
    "    Parameters:\n",
    "        X (np.ndarray): Preprocessed feature data.\n",
    "        y (np.ndarray): Corresponding labels.\n",
    "        participants (np.ndarray): Participant IDs.\n",
    "        model_path (str): Path to the saved model.\n",
    "    \"\"\"\n",
    "    model = load_model(model_path)\n",
    "    all_true, all_pred = [], []\n",
    "    prediction_details = []\n",
    "\n",
    "    for participant in np.unique(participants):\n",
    "        participant_mask = (participants == participant)\n",
    "        X_test = X[participant_mask]\n",
    "        y_test = y[participant_mask]\n",
    "\n",
    "        # Convert labels to categorical\n",
    "        y_test_categorical = to_categorical(y_test, num_classes=len(np.unique(y)))\n",
    "\n",
    "        # Predict\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "        # Collect results\n",
    "        all_true.extend(y_test)\n",
    "        all_pred.extend(y_pred)\n",
    "\n",
    "        # Collect prediction details\n",
    "        for idx, pred in enumerate(y_pred):\n",
    "            correctness = \"Correct\" if pred == y_test[idx] else \"Incorrect\"\n",
    "            prediction_details.append(f\"Participant {participant}: Predicted={pred}, Actual={y_test[idx]} ({correctness})\")\n",
    "\n",
    "    # Final evaluation\n",
    "    report = classification_report(all_true, all_pred, digits=4)\n",
    "    print(report)\n",
    "\n",
    "    # Save detailed report and predictions\n",
    "    with open(\"evaluation_results.txt\", \"w\") as eval_file:\n",
    "        eval_file.write(\"Final Accuracy: {:.4f}\\n\\n\".format(np.mean(np.array(all_true) == np.array(all_pred))))\n",
    "        eval_file.write(\"Detailed Classification Report:\\n\")\n",
    "        eval_file.write(report)\n",
    "        eval_file.write(\"\\nPrediction Details (file-level):\\n\")\n",
    "        eval_file.write(\"\\n\".join(prediction_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e130a0e-8bcd-45ee-adfc-3e7f371ef006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcml1/sigenv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and saving the model...\n",
      "Model saved to cnn_intra_model.h5\n",
      "\n",
      "Evaluating the saved model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from cnn_intra_model.h5\n",
      "\n",
      "Fold 1:\n",
      "Original X_test shape: (39, 8, 5120)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1597440 into shape (39,80,64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     evaluate_saved_model(data_directory, model_save_path)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 17\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 저장된 모델 평가\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating the saved model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mevaluate_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 49\u001b[0m, in \u001b[0;36mevaluate_saved_model\u001b[0;34m(directory, model_path)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_elements \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m64\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot reshape array of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_elements\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to match axis=-1 size of 64\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshaped X_test shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 테스트 데이터 예측\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1597440 into shape (39,80,64)"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    메인 함수: CNN 모델 생성, 저장 및 평가 실행\n",
    "    \"\"\"\n",
    "    # 데이터 디렉토리 및 모델 저장 경로 설정\n",
    "    data_directory = '/home/bcml1/2025_EMOTION/DEAP_EEG/ch_BPF'  # 데이터를 저장한 디렉토리 경로\n",
    "    model_save_path = 'cnn_intra_model.h5'  # 모델 저장 경로\n",
    "\n",
    "    # 모델 생성 및 저장\n",
    "    print(\"Creating and saving the model...\")\n",
    "    input_shape = (100, 64)  # 예시 입력 데이터 형태 (timesteps, features)\n",
    "    num_classes = 2  # 예시 클래스 개수\n",
    "    create_cnn_model(input_shape, num_classes, model_save_path)\n",
    "\n",
    "    print(\"Training the model...\")\n",
    "    train_model_intra_session(X, y, participants, model_path, result_path)\n",
    "    \n",
    "    # 저장된 모델 평가\n",
    "    print(\"\\nEvaluating the saved model...\")\n",
    "    evaluate_model(X, y, data_directory, model_save_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459fc98-587d-463a-9271-430b84a88688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
