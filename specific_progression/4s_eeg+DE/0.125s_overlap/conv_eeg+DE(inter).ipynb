{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a946caad-1f66-4e94-9418-55af09c2bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Sequential\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "# tf.config.optimizer.set_jit(False)\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" #이것을 위로 두지 않으면 GPU 대신 CPU로 설정하는 게 동작하지 않음\n",
    "# TensorFlow 로그 레벨 설정\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Failed to set memory growth: {e}\")\n",
    "else:\n",
    "    print(\"No GPU devices found. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce4c0a6-ddd7-4d41-a610-0483a94cc434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Multi-Head Self Attention\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, **kwargs):\n",
    "        super(MultiHeadSelfAttention, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        weights = self.dropout(weights)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, _ = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        # print(f\"transpose 이후 attention의 shape: {attention.shape}\")\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf324a4-57f6-420e-bcb4-5a4027da023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feed Forward Network (FFN)\n",
    "class FeedForwardNetwork(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_units, **kwargs):\n",
    "        super(FeedForwardNetwork, self).__init__(**kwargs)\n",
    "        self.dense1 = layers.Dense(dense_units, activation=tf.nn.gelu)\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.dense2 = layers.Dense(embed_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # print(f\"ffn의 input의 모양:{inputs.shape}\")\n",
    "        x = self.dense1(inputs)\n",
    "        # print(f\"dense1 layer이후:{inputs.shape}\")\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        # print(f\"dense2 layer이후:{inputs.shape}\")\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1993b621-c9ff-4ba6-a8e6-08408e203756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Temporal Encoding Layer\n",
    "class TemporalEncodingLayer(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ffn_units, **kwargs):\n",
    "        super(TemporalEncodingLayer, self).__init__(**kwargs)\n",
    "        self.mhsa = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = FeedForwardNetwork(embed_dim, ffn_units)\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # print(f\"transformer layer에 들어오는 input shape: {inputs.shape}\")\n",
    "        attn_output = self.mhsa(inputs)\n",
    "        # print(f\"mhsa layer이후 shape: {attn_output.shape}\")\n",
    "        out1 = self.layernorm1(inputs + attn_output) # Residual Connection\n",
    "        # print(f\"norm1 layer이후 shape: {out1.shape}\")\n",
    "        ffn_output = self.ffn(out1)\n",
    "        # print(f\"ffn layer이후 shape: {ffn_output.shape}\")\n",
    "        out2 = self.layernorm2(out1 + ffn_output)   # Residual Connection\n",
    "        # print(f\"norm2 layer이후 shape: {out2.shape}\")\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91cb7325-7aa2-405e-a729-9629d2fc527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class ExpandLayer(layers.Layer):\n",
    "    def __init__(self, axis=-1, **kwargs):\n",
    "        super(ExpandLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.expand_dims(inputs, axis=self.axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb180a1c-dd6f-4ab4-86c0-7c1c48e5a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes, embed_dim, num_heads, ffn_units):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    print(f\"Input shape: {inputs.shape}\")\n",
    "\n",
    "    # Spatial-Spectral CNN blocks using Conv3D\n",
    "    x = ExpandLayer(axis=-1)(inputs)  # Add channel dimension #차원 확장\n",
    "    # print(f\"After ExpandLayer: {x.shape}\")\n",
    "    x = layers.Conv3D(32, kernel_size=(3, 3, 1), activation=tf.nn.gelu, padding='same')(x) #3D 합성곱 연산\n",
    "    # print(f\"After Conv3D(32): {x.shape}\")\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 1, 2), padding='same')(x) #최대 풀링을 수행\n",
    "    # print(f\"After MaxPooling3D(pool_size=(1, 1, 2)): {x.shape}\")\n",
    "    x = layers.Conv3D(64, kernel_size=(1, 1, 5), activation=tf.nn.gelu, padding='same')(x) #3D 합성곱 연산\n",
    "    # print(f\"After Conv3D(64): {x.shape}\")\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 1, 2), padding='same')(x)\n",
    "    # print(f\"After MaxPooling3D(pool_size=(1, 1, 2)): {x.shape}\")\n",
    "    x = layers.Conv3D(128, kernel_size=(3, 3, 1), activation=tf.nn.gelu, padding='same')(x)\n",
    "    # print(f\"After Conv3D(128): {x.shape}\")\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 1, 2), padding='same')(x)\n",
    "    # print(f\"After MaxPooling3D(pool_size=(1, 1, 2)): {x.shape}\")\n",
    "    x = layers.Dropout(0.5)(x)  #\n",
    "    # print(f\"After Dropout(0.5): {x.shape}\")\n",
    "\n",
    "    # Flatten and prepare for transformer layers\n",
    "    x = layers.Flatten()(x) #다차원 텐서를 1차원 벡터로 변환(transformer에 입력하기 위해서)\n",
    "    # print(f\"After Flatten: {x.shape}\")\n",
    "    x = layers.Dense(embed_dim, activation=tf.nn.gelu)(x) #1차원 벡터(평탄화된 벡터)를 embed_dim 차원의 벡터로 변환 (relu->gelu로 활성화함수 변경)\n",
    "    # print(f\"After Dense(embed_dim): {x.shape}\")\n",
    "    \n",
    "    # Global Average Pooling instead of Flatten\n",
    "#    x = layers.GlobalAveragePooling3D()(x)  # Dimension reduction\n",
    "#    print(f\"After GlobalAveragePooling3D: {x.shape}\")  # e.g., (None, 128)\n",
    "    \n",
    "    # Dense layer with BatchNormalization and GELU for embedding\n",
    "#    x = layers.Dense(embed_dim, activation=None)(x)\n",
    "#    x = layers.BatchNormalization()(x)\n",
    "#    x = layers.Activation(tf.nn.gelu)(x)\n",
    "#    print(f\"After Dense(embed_dim) with BatchNormalization and GELU: {x.shape}\")\n",
    "\n",
    "    \n",
    "    # Emotion classification head before Transformer\n",
    "    emotion_logits = layers.Dense(num_classes, activation='softmax', name=\"emotion_logits\")(x)\n",
    "    print(f\"After Dense(num_classes): {emotion_logits.shape}\")\n",
    "\n",
    "    # Concatenate emotion predictions to transformer input\n",
    "    emotion_features = layers.Concatenate(axis=-1)([x, emotion_logits])\n",
    "    # print(f\"After Concatenate: {emotion_features.shape}\")\n",
    "    emotion_features = ExpandLayer(axis=1)(emotion_features)  # Expand for temporal dimension\n",
    "    # print(f\"After ExpandLayer for temporal dimension: {emotion_features.shape}\")\n",
    "\n",
    "    # Transformer layers\n",
    "    for i in range(3):  #2->3으로 변경\n",
    "        emotion_features = TemporalEncodingLayer(embed_dim + num_classes, num_heads, ffn_units)(emotion_features)\n",
    "        # print(f\"After TemporalEncodingLayer {i + 1}: {emotion_features.shape}\")\n",
    "\n",
    "    # # Classification head\n",
    "    x = layers.GlobalAveragePooling1D()(emotion_features)\n",
    "    # print(f\"After GlobalAveragePooling1D: {x.shape}\")\n",
    "    x = layers.Dense(66, activation=tf.nn.gelu)(x)  #64->66으로 변경\n",
    "    # print(f\"After Dense(66): {x.shape}\")\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    # print(f\"After Dropout(0.5): {x.shape}\")\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    # print(f\"Output shape: {outputs.shape}\")\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac1be1a7-cd42-4cd0-acab-4319d6a69112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_data(data_dir):\n",
    "    X, y = [], []\n",
    "    unique_files = set()\n",
    "    print(f\"Loading data from: {data_dir}\")\n",
    "\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith(\"_FB.npy\"):\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            label = 1 if \"positive\" in file_name else 0\n",
    "\n",
    "            try:\n",
    "                data = np.load(file_path)\n",
    "                reshaped_data = np.transpose(data, (0, 2, 1)) if data.ndim == 3 else data\n",
    "                X.append(reshaped_data)\n",
    "                y.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(f\"Data mismatch: X has {len(X)} samples, y has {len(y)} labels.\")\n",
    "\n",
    "    print(f\"Loaded {len(X)} samples. Labels: {np.bincount(y)}\")\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "820dc93b-e295-4fd8-9f64-00cdfe421c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Training\n",
    "def train_and_evaluate_kfold(data_dir, model_save_path, k=5):\n",
    "    X, y = load_data(data_dir)\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_metrics = []\n",
    "\n",
    "    # Class weights for imbalance handling\n",
    "    class_counts = np.bincount(y)\n",
    "    class_weights = {i: max(class_counts) / c for i, c in enumerate(class_counts)}\n",
    "    print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"Starting Fold {fold + 1}/{k}...\")\n",
    "\n",
    "        X_fold_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_fold_train, y_val = y[train_idx], y[val_idx]\n",
    "        print(f\"Training samples: {len(y_fold_train)}, Validation samples: {len(y_val)}\")\n",
    "\n",
    "        # Initialize a fresh model for each fold\n",
    "        model = build_model(\n",
    "            input_shape=X_fold_train.shape[1:],\n",
    "            num_classes=2,\n",
    "            embed_dim=64,\n",
    "            num_heads= 2,   #2(o) 3(x) 6(o)\n",
    "            ffn_units=128\n",
    "        )\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "                      loss=\"sparse_categorical_crossentropy\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "        # Learning Rate Scheduler\n",
    "        lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.0005 * (0.9 ** epoch))\n",
    "\n",
    "        # Early Stopping\n",
    "        #early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_fold_train, y_fold_train,\n",
    "            epochs=100,\n",
    "            batch_size=16,\n",
    "            class_weight=class_weights,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[lr_scheduler], #, early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Evaluate the model\n",
    "        val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "        fold_metrics.append({\"fold\": fold + 1, \"val_loss\": val_loss, \"val_accuracy\": val_accuracy})\n",
    "        print(f\"Fold {fold + 1}: Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Save the final model\n",
    "    model.save(model_save_path, save_format=\"h5\")\n",
    "    print(f\"Model saved at {model_save_path}\")\n",
    "\n",
    "    # Print average metrics\n",
    "    avg_loss = np.mean([m[\"val_loss\"] for m in fold_metrics])\n",
    "    avg_accuracy = np.mean([m[\"val_accuracy\"] for m in fold_metrics])\n",
    "    print(f\"Average Validation Loss: {avg_loss:.4f}, Average Validation Accuracy: {avg_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "384bd75e-dead-4475-a1ae-fae6fbfb57cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/bcml1/2025_EMOTION/DEAP_EEG/overlap4s_seg_conv_ch_BPF+DE/train_overlap0.125\n",
      "Loaded 81787 samples. Labels: [39882 41905]\n",
      "Class weights: {0: 1.0507246376811594, 1: 1.0}\n",
      "Starting Fold 1/5...\n",
      "Training samples: 65429, Validation samples: 16358\n",
      "Input shape: (None, 4, 8, 513)\n",
      "After Dense(num_classes): (None, 2)\n",
      "Epoch 1/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 13ms/step - accuracy: 0.5126 - loss: 0.7281 - val_accuracy: 0.6535 - val_loss: 0.6225 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9ms/step - accuracy: 0.6614 - loss: 0.6140 - val_accuracy: 0.7668 - val_loss: 0.4713 - learning_rate: 4.5000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.8080 - loss: 0.4246 - val_accuracy: 0.8470 - val_loss: 0.3459 - learning_rate: 4.0500e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.8862 - loss: 0.2852 - val_accuracy: 0.8862 - val_loss: 0.2669 - learning_rate: 3.6450e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9343 - loss: 0.1800 - val_accuracy: 0.9158 - val_loss: 0.2396 - learning_rate: 3.2805e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9609 - loss: 0.1124 - val_accuracy: 0.9282 - val_loss: 0.2310 - learning_rate: 2.9525e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9756 - loss: 0.0764 - val_accuracy: 0.9350 - val_loss: 0.2749 - learning_rate: 2.6572e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9851 - loss: 0.0499 - val_accuracy: 0.9381 - val_loss: 0.2122 - learning_rate: 2.3915e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9894 - loss: 0.0365 - val_accuracy: 0.9244 - val_loss: 0.2467 - learning_rate: 2.1523e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0249 - val_accuracy: 0.9434 - val_loss: 0.2320 - learning_rate: 1.9371e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0205 - val_accuracy: 0.9358 - val_loss: 0.2759 - learning_rate: 1.7434e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0165 - val_accuracy: 0.9498 - val_loss: 0.2795 - learning_rate: 1.5691e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9965 - loss: 0.0129 - val_accuracy: 0.9503 - val_loss: 0.2462 - learning_rate: 1.4121e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9972 - loss: 0.0113 - val_accuracy: 0.9512 - val_loss: 0.2591 - learning_rate: 1.2709e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9976 - loss: 0.0102 - val_accuracy: 0.9515 - val_loss: 0.2752 - learning_rate: 1.1438e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0100 - val_accuracy: 0.9445 - val_loss: 0.3298 - learning_rate: 1.0295e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 0.9527 - val_loss: 0.3087 - learning_rate: 9.2651e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9549 - val_loss: 0.3171 - learning_rate: 8.3386e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0059 - val_accuracy: 0.9555 - val_loss: 0.2628 - learning_rate: 7.5047e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 0.9580 - val_loss: 0.2747 - learning_rate: 6.7543e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9564 - val_loss: 0.2914 - learning_rate: 6.0788e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.9565 - val_loss: 0.3039 - learning_rate: 5.4709e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9550 - val_loss: 0.3744 - learning_rate: 4.9239e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9556 - val_loss: 0.3435 - learning_rate: 4.4315e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.9520 - val_loss: 0.3994 - learning_rate: 3.9883e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9549 - val_loss: 0.3912 - learning_rate: 3.5895e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9578 - val_loss: 0.3245 - learning_rate: 3.2305e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9591 - val_loss: 0.3448 - learning_rate: 2.9075e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 9.8515e-04 - val_accuracy: 0.9584 - val_loss: 0.3520 - learning_rate: 2.6167e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9590 - val_loss: 0.3348 - learning_rate: 2.3551e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9589 - val_loss: 0.3684 - learning_rate: 2.1196e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 9.7598e-04 - val_accuracy: 0.9587 - val_loss: 0.3721 - learning_rate: 1.9076e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 8.6457e-04 - val_accuracy: 0.9591 - val_loss: 0.3955 - learning_rate: 1.7168e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0034 - val_accuracy: 0.9597 - val_loss: 0.3719 - learning_rate: 1.5452e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9601 - val_loss: 0.3872 - learning_rate: 1.3906e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 4.8123e-04 - val_accuracy: 0.9603 - val_loss: 0.3953 - learning_rate: 1.2516e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.3064e-04 - val_accuracy: 0.9610 - val_loss: 0.3880 - learning_rate: 1.1264e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 5.4600e-04 - val_accuracy: 0.9616 - val_loss: 0.4114 - learning_rate: 1.0138e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 9.1195e-04 - val_accuracy: 0.9601 - val_loss: 0.4068 - learning_rate: 9.1240e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 3.0826e-04 - val_accuracy: 0.9587 - val_loss: 0.4271 - learning_rate: 8.2116e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9602 - val_loss: 0.4032 - learning_rate: 7.3904e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 7.2241e-04 - val_accuracy: 0.9612 - val_loss: 0.3934 - learning_rate: 6.6514e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 2.3255e-04 - val_accuracy: 0.9612 - val_loss: 0.3989 - learning_rate: 5.9863e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 3.3243e-04 - val_accuracy: 0.9608 - val_loss: 0.4193 - learning_rate: 5.3876e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.0826e-04 - val_accuracy: 0.9604 - val_loss: 0.4404 - learning_rate: 4.8489e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9601 - val_loss: 0.4315 - learning_rate: 4.3640e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.4159e-04 - val_accuracy: 0.9608 - val_loss: 0.4258 - learning_rate: 3.9276e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 7.3600e-04 - val_accuracy: 0.9612 - val_loss: 0.4171 - learning_rate: 3.5348e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 4.2200e-04 - val_accuracy: 0.9616 - val_loss: 0.4180 - learning_rate: 3.1813e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 5.2123e-04 - val_accuracy: 0.9611 - val_loss: 0.4152 - learning_rate: 2.8632e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.5854e-04 - val_accuracy: 0.9615 - val_loss: 0.4169 - learning_rate: 2.5769e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.4401e-04 - val_accuracy: 0.9613 - val_loss: 0.4159 - learning_rate: 2.3192e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 1.5860e-04 - val_accuracy: 0.9612 - val_loss: 0.4203 - learning_rate: 2.0873e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2434e-04 - val_accuracy: 0.9615 - val_loss: 0.4276 - learning_rate: 1.8786e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.5610e-04 - val_accuracy: 0.9614 - val_loss: 0.4275 - learning_rate: 1.6907e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.7084e-04 - val_accuracy: 0.9617 - val_loss: 0.4265 - learning_rate: 1.5216e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 2.5979e-04 - val_accuracy: 0.9614 - val_loss: 0.4272 - learning_rate: 1.3695e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 8.3178e-04 - val_accuracy: 0.9617 - val_loss: 0.4259 - learning_rate: 1.2325e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.5121e-04 - val_accuracy: 0.9615 - val_loss: 0.4273 - learning_rate: 1.1093e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.6058e-04 - val_accuracy: 0.9619 - val_loss: 0.4283 - learning_rate: 9.9834e-07\n",
      "Epoch 61/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 1.9433e-04 - val_accuracy: 0.9618 - val_loss: 0.4291 - learning_rate: 8.9851e-07\n",
      "Epoch 62/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 2.6401e-04 - val_accuracy: 0.9615 - val_loss: 0.4317 - learning_rate: 8.0865e-07\n",
      "Epoch 63/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.3740e-04 - val_accuracy: 0.9615 - val_loss: 0.4349 - learning_rate: 7.2779e-07\n",
      "Epoch 64/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.3086e-04 - val_accuracy: 0.9616 - val_loss: 0.4357 - learning_rate: 6.5501e-07\n",
      "Epoch 65/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.3785e-04 - val_accuracy: 0.9614 - val_loss: 0.4341 - learning_rate: 5.8951e-07\n",
      "Epoch 66/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 7.3030e-04 - val_accuracy: 0.9614 - val_loss: 0.4346 - learning_rate: 5.3056e-07\n",
      "Epoch 67/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.3112e-04 - val_accuracy: 0.9615 - val_loss: 0.4343 - learning_rate: 4.7750e-07\n",
      "Epoch 68/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1727e-04 - val_accuracy: 0.9615 - val_loss: 0.4348 - learning_rate: 4.2975e-07\n",
      "Epoch 69/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 1.5177e-04 - val_accuracy: 0.9615 - val_loss: 0.4348 - learning_rate: 3.8678e-07\n",
      "Epoch 70/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.6201e-04 - val_accuracy: 0.9613 - val_loss: 0.4347 - learning_rate: 3.4810e-07\n",
      "Epoch 71/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7543e-05 - val_accuracy: 0.9614 - val_loss: 0.4359 - learning_rate: 3.1329e-07\n",
      "Epoch 72/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.8960e-04 - val_accuracy: 0.9612 - val_loss: 0.4359 - learning_rate: 2.8196e-07\n",
      "Epoch 73/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.5809e-04 - val_accuracy: 0.9613 - val_loss: 0.4355 - learning_rate: 2.5376e-07\n",
      "Epoch 74/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4456e-04 - val_accuracy: 0.9612 - val_loss: 0.4360 - learning_rate: 2.2839e-07\n",
      "Epoch 75/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 1.4919e-04 - val_accuracy: 0.9613 - val_loss: 0.4367 - learning_rate: 2.0555e-07\n",
      "Epoch 76/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 2.1057e-04 - val_accuracy: 0.9612 - val_loss: 0.4366 - learning_rate: 1.8499e-07\n",
      "Epoch 77/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 8.4334e-04 - val_accuracy: 0.9615 - val_loss: 0.4369 - learning_rate: 1.6649e-07\n",
      "Epoch 78/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0138e-04 - val_accuracy: 0.9617 - val_loss: 0.4372 - learning_rate: 1.4985e-07\n",
      "Epoch 79/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.7134e-04 - val_accuracy: 0.9617 - val_loss: 0.4373 - learning_rate: 1.3486e-07\n",
      "Epoch 80/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 2.2402e-04 - val_accuracy: 0.9618 - val_loss: 0.4375 - learning_rate: 1.2137e-07\n",
      "Epoch 81/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1279e-04 - val_accuracy: 0.9617 - val_loss: 0.4376 - learning_rate: 1.0924e-07\n",
      "Epoch 82/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.4494e-05 - val_accuracy: 0.9615 - val_loss: 0.4382 - learning_rate: 9.8314e-08\n",
      "Epoch 83/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.9382e-04 - val_accuracy: 0.9616 - val_loss: 0.4381 - learning_rate: 8.8482e-08\n",
      "Epoch 84/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.3101e-04 - val_accuracy: 0.9615 - val_loss: 0.4380 - learning_rate: 7.9634e-08\n",
      "Epoch 85/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 5.6643e-04 - val_accuracy: 0.9615 - val_loss: 0.4379 - learning_rate: 7.1671e-08\n",
      "Epoch 86/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 1.6547e-04 - val_accuracy: 0.9617 - val_loss: 0.4379 - learning_rate: 6.4504e-08\n",
      "Epoch 87/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.8387e-05 - val_accuracy: 0.9617 - val_loss: 0.4380 - learning_rate: 5.8053e-08\n",
      "Epoch 88/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 8.1984e-04 - val_accuracy: 0.9616 - val_loss: 0.4383 - learning_rate: 5.2248e-08\n",
      "Epoch 89/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.0160e-05 - val_accuracy: 0.9617 - val_loss: 0.4383 - learning_rate: 4.7023e-08\n",
      "Epoch 90/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 3.1521e-04 - val_accuracy: 0.9615 - val_loss: 0.4383 - learning_rate: 4.2321e-08\n",
      "Epoch 91/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.4128e-04 - val_accuracy: 0.9616 - val_loss: 0.4382 - learning_rate: 3.8089e-08\n",
      "Epoch 92/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 3.1051e-04 - val_accuracy: 0.9615 - val_loss: 0.4382 - learning_rate: 3.4280e-08\n",
      "Epoch 93/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.5224e-04 - val_accuracy: 0.9615 - val_loss: 0.4382 - learning_rate: 3.0852e-08\n",
      "Epoch 94/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.6998e-04 - val_accuracy: 0.9615 - val_loss: 0.4383 - learning_rate: 2.7767e-08\n",
      "Epoch 95/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4462e-04 - val_accuracy: 0.9616 - val_loss: 0.4383 - learning_rate: 2.4990e-08\n",
      "Epoch 96/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 7.5968e-04 - val_accuracy: 0.9617 - val_loss: 0.4383 - learning_rate: 2.2491e-08\n",
      "Epoch 97/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4549e-04 - val_accuracy: 0.9617 - val_loss: 0.4384 - learning_rate: 2.0242e-08\n",
      "Epoch 98/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 2.5263e-04 - val_accuracy: 0.9617 - val_loss: 0.4384 - learning_rate: 1.8218e-08\n",
      "Epoch 99/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 2.5031e-04 - val_accuracy: 0.9617 - val_loss: 0.4384 - learning_rate: 1.6396e-08\n",
      "Epoch 100/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.5442e-04 - val_accuracy: 0.9617 - val_loss: 0.4384 - learning_rate: 1.4756e-08\n",
      "Fold 1: Validation Loss: 0.4384, Validation Accuracy: 0.9617\n",
      "Starting Fold 2/5...\n",
      "Training samples: 65429, Validation samples: 16358\n",
      "Input shape: (None, 4, 8, 513)\n",
      "After Dense(num_classes): (None, 2)\n",
      "Epoch 1/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 13ms/step - accuracy: 0.5150 - loss: 0.7290 - val_accuracy: 0.5873 - val_loss: 0.6409 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9ms/step - accuracy: 0.6843 - loss: 0.5907 - val_accuracy: 0.8163 - val_loss: 0.4052 - learning_rate: 4.5000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.8311 - loss: 0.3857 - val_accuracy: 0.8616 - val_loss: 0.3088 - learning_rate: 4.0500e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9ms/step - accuracy: 0.9045 - loss: 0.2470 - val_accuracy: 0.9011 - val_loss: 0.2370 - learning_rate: 3.6450e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9425 - loss: 0.1607 - val_accuracy: 0.9113 - val_loss: 0.2497 - learning_rate: 3.2805e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9640 - loss: 0.1044 - val_accuracy: 0.9275 - val_loss: 0.2042 - learning_rate: 2.9525e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9797 - loss: 0.0655 - val_accuracy: 0.9312 - val_loss: 0.2618 - learning_rate: 2.6572e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9857 - loss: 0.0470 - val_accuracy: 0.9358 - val_loss: 0.2298 - learning_rate: 2.3915e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9876 - loss: 0.0436 - val_accuracy: 0.9378 - val_loss: 0.2617 - learning_rate: 2.1523e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9926 - loss: 0.0264 - val_accuracy: 0.9436 - val_loss: 0.2399 - learning_rate: 1.9371e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0218 - val_accuracy: 0.9469 - val_loss: 0.2111 - learning_rate: 1.7434e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.0149 - val_accuracy: 0.9438 - val_loss: 0.2404 - learning_rate: 1.5691e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9957 - loss: 0.0174 - val_accuracy: 0.9494 - val_loss: 0.2284 - learning_rate: 1.4121e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9970 - loss: 0.0107 - val_accuracy: 0.9513 - val_loss: 0.2482 - learning_rate: 1.2709e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0069 - val_accuracy: 0.9427 - val_loss: 0.3172 - learning_rate: 1.1438e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0077 - val_accuracy: 0.9522 - val_loss: 0.2378 - learning_rate: 1.0295e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9518 - val_loss: 0.3003 - learning_rate: 9.2651e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.9508 - val_loss: 0.2812 - learning_rate: 8.3386e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 0.9497 - val_loss: 0.2976 - learning_rate: 7.5047e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9552 - val_loss: 0.2967 - learning_rate: 6.7543e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.9538 - val_loss: 0.3887 - learning_rate: 6.0788e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0036 - val_accuracy: 0.9565 - val_loss: 0.3204 - learning_rate: 5.4709e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9585 - val_loss: 0.3064 - learning_rate: 4.9239e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9529 - val_loss: 0.4004 - learning_rate: 4.4315e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0032 - val_accuracy: 0.9564 - val_loss: 0.3718 - learning_rate: 3.9883e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9567 - val_loss: 0.3726 - learning_rate: 3.5895e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9584 - val_loss: 0.3450 - learning_rate: 3.2305e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9573 - val_loss: 0.3871 - learning_rate: 2.9075e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9567 - val_loss: 0.3776 - learning_rate: 2.6167e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.6902e-04 - val_accuracy: 0.9571 - val_loss: 0.4361 - learning_rate: 2.3551e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.2969e-04 - val_accuracy: 0.9581 - val_loss: 0.4048 - learning_rate: 2.1196e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 3.7477e-04 - val_accuracy: 0.9579 - val_loss: 0.4240 - learning_rate: 1.9076e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9595 - val_loss: 0.4102 - learning_rate: 1.7168e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 8.4155e-04 - val_accuracy: 0.9600 - val_loss: 0.4206 - learning_rate: 1.5452e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 4.3589e-04 - val_accuracy: 0.9598 - val_loss: 0.4383 - learning_rate: 1.3906e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.9590 - val_loss: 0.4540 - learning_rate: 1.2516e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9590 - val_loss: 0.4570 - learning_rate: 1.1264e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9603 - val_loss: 0.4477 - learning_rate: 1.0138e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 4.8364e-04 - val_accuracy: 0.9596 - val_loss: 0.4562 - learning_rate: 9.1240e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2999e-04 - val_accuracy: 0.9598 - val_loss: 0.4733 - learning_rate: 8.2116e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 4.1142e-04 - val_accuracy: 0.9608 - val_loss: 0.4834 - learning_rate: 7.3904e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 3.8096e-04 - val_accuracy: 0.9609 - val_loss: 0.4877 - learning_rate: 6.6514e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.6053e-04 - val_accuracy: 0.9603 - val_loss: 0.4979 - learning_rate: 5.9863e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.4986e-04 - val_accuracy: 0.9599 - val_loss: 0.4963 - learning_rate: 5.3876e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9603 - val_loss: 0.4901 - learning_rate: 4.8489e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.3003e-04 - val_accuracy: 0.9612 - val_loss: 0.4858 - learning_rate: 4.3640e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 2.0876e-04 - val_accuracy: 0.9609 - val_loss: 0.4896 - learning_rate: 3.9276e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9609 - val_loss: 0.4998 - learning_rate: 3.5348e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.8772e-04 - val_accuracy: 0.9604 - val_loss: 0.5001 - learning_rate: 3.1813e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.3489e-04 - val_accuracy: 0.9613 - val_loss: 0.4981 - learning_rate: 2.8632e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.9603 - val_loss: 0.4916 - learning_rate: 2.5769e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.6644e-04 - val_accuracy: 0.9606 - val_loss: 0.4958 - learning_rate: 2.3192e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 8.4315e-04 - val_accuracy: 0.9604 - val_loss: 0.4957 - learning_rate: 2.0873e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.6824e-04 - val_accuracy: 0.9604 - val_loss: 0.4968 - learning_rate: 1.8786e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.3113e-04 - val_accuracy: 0.9608 - val_loss: 0.4936 - learning_rate: 1.6907e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.1303e-05 - val_accuracy: 0.9603 - val_loss: 0.4977 - learning_rate: 1.5216e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 5.8443e-04 - val_accuracy: 0.9606 - val_loss: 0.4986 - learning_rate: 1.3695e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 3.5048e-04 - val_accuracy: 0.9606 - val_loss: 0.4995 - learning_rate: 1.2325e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9612 - val_loss: 0.5013 - learning_rate: 1.1093e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 2.1025e-04 - val_accuracy: 0.9614 - val_loss: 0.4966 - learning_rate: 9.9834e-07\n",
      "Epoch 61/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.4700e-04 - val_accuracy: 0.9616 - val_loss: 0.4975 - learning_rate: 8.9851e-07\n",
      "Epoch 62/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2330e-04 - val_accuracy: 0.9617 - val_loss: 0.4990 - learning_rate: 8.0865e-07\n",
      "Epoch 63/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5509e-04 - val_accuracy: 0.9615 - val_loss: 0.4973 - learning_rate: 7.2779e-07\n",
      "Epoch 64/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.0625e-04 - val_accuracy: 0.9617 - val_loss: 0.4982 - learning_rate: 6.5501e-07\n",
      "Epoch 65/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.5877e-04 - val_accuracy: 0.9617 - val_loss: 0.4965 - learning_rate: 5.8951e-07\n",
      "Epoch 66/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 2.5274e-04 - val_accuracy: 0.9612 - val_loss: 0.4968 - learning_rate: 5.3056e-07\n",
      "Epoch 67/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 7.5927e-04 - val_accuracy: 0.9614 - val_loss: 0.4967 - learning_rate: 4.7750e-07\n",
      "Epoch 68/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9614 - val_loss: 0.4974 - learning_rate: 4.2975e-07\n",
      "Epoch 69/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 3.9965e-04 - val_accuracy: 0.9614 - val_loss: 0.4976 - learning_rate: 3.8678e-07\n",
      "Epoch 70/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.6001e-04 - val_accuracy: 0.9615 - val_loss: 0.4989 - learning_rate: 3.4810e-07\n",
      "Epoch 71/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 2.9723e-04 - val_accuracy: 0.9614 - val_loss: 0.4989 - learning_rate: 3.1329e-07\n",
      "Epoch 72/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4061e-04 - val_accuracy: 0.9614 - val_loss: 0.4998 - learning_rate: 2.8196e-07\n",
      "Epoch 73/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3058e-04 - val_accuracy: 0.9614 - val_loss: 0.4989 - learning_rate: 2.5376e-07\n",
      "Epoch 74/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.0138e-05 - val_accuracy: 0.9614 - val_loss: 0.4993 - learning_rate: 2.2839e-07\n",
      "Epoch 75/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2294e-04 - val_accuracy: 0.9614 - val_loss: 0.4997 - learning_rate: 2.0555e-07\n",
      "Epoch 76/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 3.3349e-04 - val_accuracy: 0.9615 - val_loss: 0.4997 - learning_rate: 1.8499e-07\n",
      "Epoch 77/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5983e-04 - val_accuracy: 0.9614 - val_loss: 0.4991 - learning_rate: 1.6649e-07\n",
      "Epoch 78/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 3.3906e-04 - val_accuracy: 0.9615 - val_loss: 0.4990 - learning_rate: 1.4985e-07\n",
      "Epoch 79/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 3.4869e-04 - val_accuracy: 0.9614 - val_loss: 0.4989 - learning_rate: 1.3486e-07\n",
      "Epoch 80/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 3.6315e-04 - val_accuracy: 0.9614 - val_loss: 0.4990 - learning_rate: 1.2137e-07\n",
      "Epoch 81/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 3.5482e-04 - val_accuracy: 0.9614 - val_loss: 0.4992 - learning_rate: 1.0924e-07\n",
      "Epoch 82/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 2.9041e-04 - val_accuracy: 0.9614 - val_loss: 0.4995 - learning_rate: 9.8314e-08\n",
      "Epoch 83/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 8.9508e-04 - val_accuracy: 0.9614 - val_loss: 0.4994 - learning_rate: 8.8482e-08\n",
      "Epoch 84/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 7.0226e-04 - val_accuracy: 0.9615 - val_loss: 0.4998 - learning_rate: 7.9634e-08\n",
      "Epoch 85/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.4186e-04 - val_accuracy: 0.9615 - val_loss: 0.4998 - learning_rate: 7.1671e-08\n",
      "Epoch 86/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.9498e-04 - val_accuracy: 0.9615 - val_loss: 0.4999 - learning_rate: 6.4504e-08\n",
      "Epoch 87/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.8477e-04 - val_accuracy: 0.9615 - val_loss: 0.4999 - learning_rate: 5.8053e-08\n",
      "Epoch 88/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.3160e-04 - val_accuracy: 0.9615 - val_loss: 0.5000 - learning_rate: 5.2248e-08\n",
      "Epoch 89/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.2116e-04 - val_accuracy: 0.9615 - val_loss: 0.5000 - learning_rate: 4.7023e-08\n",
      "Epoch 90/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 3.6504e-04 - val_accuracy: 0.9615 - val_loss: 0.5001 - learning_rate: 4.2321e-08\n",
      "Epoch 91/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 2.1947e-04 - val_accuracy: 0.9615 - val_loss: 0.5001 - learning_rate: 3.8089e-08\n",
      "Epoch 92/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 7.0245e-04 - val_accuracy: 0.9615 - val_loss: 0.5001 - learning_rate: 3.4280e-08\n",
      "Epoch 93/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 5.5691e-04 - val_accuracy: 0.9615 - val_loss: 0.5001 - learning_rate: 3.0852e-08\n",
      "Epoch 94/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9615 - val_loss: 0.5001 - learning_rate: 2.7767e-08\n",
      "Epoch 95/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 3.8279e-04 - val_accuracy: 0.9615 - val_loss: 0.5002 - learning_rate: 2.4990e-08\n",
      "Epoch 96/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.6545e-04 - val_accuracy: 0.9615 - val_loss: 0.5002 - learning_rate: 2.2491e-08\n",
      "Epoch 97/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4266e-04 - val_accuracy: 0.9615 - val_loss: 0.5003 - learning_rate: 2.0242e-08\n",
      "Epoch 98/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.1969e-04 - val_accuracy: 0.9614 - val_loss: 0.5003 - learning_rate: 1.8218e-08\n",
      "Epoch 99/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4434e-04 - val_accuracy: 0.9615 - val_loss: 0.5002 - learning_rate: 1.6396e-08\n",
      "Epoch 100/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 2.0615e-04 - val_accuracy: 0.9615 - val_loss: 0.5003 - learning_rate: 1.4756e-08\n",
      "Fold 2: Validation Loss: 0.5003, Validation Accuracy: 0.9615\n",
      "Starting Fold 3/5...\n",
      "Training samples: 65430, Validation samples: 16357\n",
      "Input shape: (None, 4, 8, 513)\n",
      "After Dense(num_classes): (None, 2)\n",
      "Epoch 1/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 13ms/step - accuracy: 0.5018 - loss: 0.7393 - val_accuracy: 0.6019 - val_loss: 0.6652 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.6258 - loss: 0.6659 - val_accuracy: 0.7204 - val_loss: 0.5329 - learning_rate: 4.5000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.7646 - loss: 0.4958 - val_accuracy: 0.8465 - val_loss: 0.3444 - learning_rate: 4.0500e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.8610 - loss: 0.3331 - val_accuracy: 0.8822 - val_loss: 0.2781 - learning_rate: 3.6450e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9180 - loss: 0.2224 - val_accuracy: 0.8934 - val_loss: 0.2727 - learning_rate: 3.2805e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9471 - loss: 0.1533 - val_accuracy: 0.9140 - val_loss: 0.2543 - learning_rate: 2.9525e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9677 - loss: 0.1059 - val_accuracy: 0.9301 - val_loss: 0.2303 - learning_rate: 2.6572e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9782 - loss: 0.0721 - val_accuracy: 0.9270 - val_loss: 0.2612 - learning_rate: 2.3915e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9848 - loss: 0.0545 - val_accuracy: 0.9414 - val_loss: 0.2088 - learning_rate: 2.1523e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9884 - loss: 0.0437 - val_accuracy: 0.9397 - val_loss: 0.2109 - learning_rate: 1.9371e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0354 - val_accuracy: 0.9445 - val_loss: 0.2374 - learning_rate: 1.7434e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 0.0269 - val_accuracy: 0.9458 - val_loss: 0.2209 - learning_rate: 1.5691e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9936 - loss: 0.0256 - val_accuracy: 0.9485 - val_loss: 0.2584 - learning_rate: 1.4121e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9953 - loss: 0.0196 - val_accuracy: 0.9508 - val_loss: 0.2077 - learning_rate: 1.2709e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9966 - loss: 0.0160 - val_accuracy: 0.9512 - val_loss: 0.2154 - learning_rate: 1.1438e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9963 - loss: 0.0189 - val_accuracy: 0.9346 - val_loss: 0.2891 - learning_rate: 1.0295e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0147 - val_accuracy: 0.9524 - val_loss: 0.2853 - learning_rate: 9.2651e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0114 - val_accuracy: 0.9532 - val_loss: 0.2680 - learning_rate: 8.3386e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9972 - loss: 0.0111 - val_accuracy: 0.9516 - val_loss: 0.2598 - learning_rate: 7.5047e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0095 - val_accuracy: 0.9530 - val_loss: 0.2756 - learning_rate: 6.7543e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0065 - val_accuracy: 0.9555 - val_loss: 0.2357 - learning_rate: 6.0788e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9990 - loss: 0.0056 - val_accuracy: 0.9559 - val_loss: 0.2839 - learning_rate: 5.4709e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0080 - val_accuracy: 0.9573 - val_loss: 0.2274 - learning_rate: 4.9239e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0051 - val_accuracy: 0.9545 - val_loss: 0.2598 - learning_rate: 4.4315e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0073 - val_accuracy: 0.9561 - val_loss: 0.2767 - learning_rate: 3.9883e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0050 - val_accuracy: 0.9570 - val_loss: 0.2905 - learning_rate: 3.5895e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0056 - val_accuracy: 0.9561 - val_loss: 0.3060 - learning_rate: 3.2305e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0037 - val_accuracy: 0.9586 - val_loss: 0.2886 - learning_rate: 2.9075e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0039 - val_accuracy: 0.9562 - val_loss: 0.3102 - learning_rate: 2.6167e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0035 - val_accuracy: 0.9577 - val_loss: 0.3420 - learning_rate: 2.3551e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0045 - val_accuracy: 0.9574 - val_loss: 0.3487 - learning_rate: 2.1196e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0049 - val_accuracy: 0.9560 - val_loss: 0.3629 - learning_rate: 1.9076e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0068 - val_accuracy: 0.9590 - val_loss: 0.3279 - learning_rate: 1.7168e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0045 - val_accuracy: 0.9595 - val_loss: 0.3357 - learning_rate: 1.5452e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0037 - val_accuracy: 0.9568 - val_loss: 0.3280 - learning_rate: 1.3906e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0039 - val_accuracy: 0.9589 - val_loss: 0.3339 - learning_rate: 1.2516e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 0.9572 - val_loss: 0.3509 - learning_rate: 1.1264e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0034 - val_accuracy: 0.9597 - val_loss: 0.3396 - learning_rate: 1.0138e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9604 - val_loss: 0.3395 - learning_rate: 9.1240e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0053 - val_accuracy: 0.9597 - val_loss: 0.3428 - learning_rate: 8.2116e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.9598 - val_loss: 0.3582 - learning_rate: 7.3904e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.9596 - val_loss: 0.3641 - learning_rate: 6.6514e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0031 - val_accuracy: 0.9601 - val_loss: 0.3551 - learning_rate: 5.9863e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0054 - val_accuracy: 0.9599 - val_loss: 0.3480 - learning_rate: 5.3876e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0057 - val_accuracy: 0.9597 - val_loss: 0.3527 - learning_rate: 4.8489e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0040 - val_accuracy: 0.9603 - val_loss: 0.3589 - learning_rate: 4.3640e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0037 - val_accuracy: 0.9603 - val_loss: 0.3518 - learning_rate: 3.9276e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 0.9599 - val_loss: 0.3537 - learning_rate: 3.5348e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0044 - val_accuracy: 0.9603 - val_loss: 0.3540 - learning_rate: 3.1813e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0031 - val_accuracy: 0.9594 - val_loss: 0.3496 - learning_rate: 2.8632e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 0.9601 - val_loss: 0.3653 - learning_rate: 1.8786e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.9599 - val_loss: 0.3628 - learning_rate: 1.6907e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.9603 - val_loss: 0.3631 - learning_rate: 1.5216e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0037 - val_accuracy: 0.9598 - val_loss: 0.3606 - learning_rate: 1.3695e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m3668/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0032 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9991 - loss: 0.0048 - val_accuracy: 0.9585 - val_loss: 0.2785 - learning_rate: 5.4709e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0044 - val_accuracy: 0.9572 - val_loss: 0.3144 - learning_rate: 4.9239e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.9583 - val_loss: 0.3141 - learning_rate: 4.4315e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9596 - val_loss: 0.2874 - learning_rate: 3.9883e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9548 - val_loss: 0.3889 - learning_rate: 3.5895e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0041 - val_accuracy: 0.9552 - val_loss: 0.3572 - learning_rate: 3.2305e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9589 - val_loss: 0.3166 - learning_rate: 2.9075e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9590 - val_loss: 0.3122 - learning_rate: 2.6167e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9571 - val_loss: 0.3714 - learning_rate: 2.3551e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0026 - val_accuracy: 0.9607 - val_loss: 0.3419 - learning_rate: 2.1196e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9601 - val_loss: 0.3488 - learning_rate: 1.9076e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9606 - val_loss: 0.3324 - learning_rate: 1.7168e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 8.0074e-04 - val_accuracy: 0.9609 - val_loss: 0.3606 - learning_rate: 1.5452e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0021 - val_accuracy: 0.9608 - val_loss: 0.3551 - learning_rate: 1.3906e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9603 - val_loss: 0.3748 - learning_rate: 1.2516e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9598 - val_loss: 0.4059 - learning_rate: 1.1264e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9602 - val_loss: 0.3919 - learning_rate: 1.0138e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9598 - val_loss: 0.3810 - learning_rate: 9.1240e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9602 - val_loss: 0.3693 - learning_rate: 8.2116e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 9.5956e-04 - val_accuracy: 0.9609 - val_loss: 0.3870 - learning_rate: 7.3904e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9593 - val_loss: 0.3943 - learning_rate: 6.6514e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9606 - val_loss: 0.3833 - learning_rate: 5.9863e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9598 - val_loss: 0.3943 - learning_rate: 5.3876e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0029 - val_accuracy: 0.9608 - val_loss: 0.3946 - learning_rate: 4.8489e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9605 - val_loss: 0.3852 - learning_rate: 4.3640e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9604 - val_loss: 0.3944 - learning_rate: 3.9276e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9605 - val_loss: 0.4005 - learning_rate: 3.5348e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.5060e-04 - val_accuracy: 0.9604 - val_loss: 0.4059 - learning_rate: 3.1813e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 7.4162e-04 - val_accuracy: 0.9609 - val_loss: 0.3987 - learning_rate: 2.8632e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 8.9099e-04 - val_accuracy: 0.9614 - val_loss: 0.4031 - learning_rate: 2.5769e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 9.9386e-04 - val_accuracy: 0.9601 - val_loss: 0.4056 - learning_rate: 2.3192e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 9.5121e-04 - val_accuracy: 0.9603 - val_loss: 0.4078 - learning_rate: 2.0873e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 9.8539e-04 - val_accuracy: 0.9609 - val_loss: 0.4067 - learning_rate: 1.3695e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 9.4001e-04 - val_accuracy: 0.9610 - val_loss: 0.4100 - learning_rate: 1.2325e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.8834e-04 - val_accuracy: 0.9610 - val_loss: 0.4153 - learning_rate: 1.1093e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 3.9937e-04 - val_accuracy: 0.9606 - val_loss: 0.4167 - learning_rate: 9.9834e-07\n",
      "Epoch 61/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 9.2213e-04 - val_accuracy: 0.9607 - val_loss: 0.4189 - learning_rate: 8.9851e-07\n",
      "Epoch 62/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9604 - val_loss: 0.4218 - learning_rate: 8.0865e-07\n",
      "Epoch 63/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9604 - val_loss: 0.4224 - learning_rate: 7.2779e-07\n",
      "Epoch 64/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9607 - val_loss: 0.4208 - learning_rate: 6.5501e-07\n",
      "Epoch 65/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.3183e-04 - val_accuracy: 0.9608 - val_loss: 0.4195 - learning_rate: 5.8951e-07\n",
      "Epoch 66/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.7111e-04 - val_accuracy: 0.9609 - val_loss: 0.4195 - learning_rate: 5.3056e-07\n",
      "Epoch 67/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 3.7350e-04 - val_accuracy: 0.9611 - val_loss: 0.4194 - learning_rate: 4.7750e-07\n",
      "Epoch 68/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 6.9945e-04 - val_accuracy: 0.9611 - val_loss: 0.4202 - learning_rate: 4.2975e-07\n",
      "Epoch 69/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 9.9120e-04 - val_accuracy: 0.9612 - val_loss: 0.4188 - learning_rate: 3.8678e-07\n",
      "Epoch 70/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0025 - val_accuracy: 0.9611 - val_loss: 0.4194 - learning_rate: 3.4810e-07\n",
      "Epoch 71/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.9609 - val_loss: 0.4204 - learning_rate: 3.1329e-07\n",
      "Epoch 72/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9612 - val_loss: 0.4182 - learning_rate: 2.8196e-07\n",
      "Epoch 73/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.5292e-04 - val_accuracy: 0.9612 - val_loss: 0.4186 - learning_rate: 2.5376e-07\n",
      "Epoch 74/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9612 - val_loss: 0.4182 - learning_rate: 2.2839e-07\n",
      "Epoch 75/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9612 - val_loss: 0.4176 - learning_rate: 2.0555e-07\n",
      "Epoch 76/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.9612 - val_loss: 0.4178 - learning_rate: 1.8499e-07\n",
      "Epoch 77/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 16ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9612 - val_loss: 0.4178 - learning_rate: 1.6649e-07\n",
      "Epoch 78/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.9612 - val_loss: 0.4177 - learning_rate: 1.4985e-07\n",
      "Epoch 79/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9612 - val_loss: 0.4172 - learning_rate: 1.3486e-07\n",
      "Epoch 80/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 4.6567e-04 - val_accuracy: 0.9612 - val_loss: 0.4172 - learning_rate: 1.2137e-07\n",
      "Epoch 81/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0027 - val_accuracy: 0.9612 - val_loss: 0.4171 - learning_rate: 1.0924e-07\n",
      "Epoch 82/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9613 - val_loss: 0.4170 - learning_rate: 9.8314e-08\n",
      "Epoch 83/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.9612 - val_loss: 0.4170 - learning_rate: 8.8482e-08\n",
      "Epoch 84/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.3655e-04 - val_accuracy: 0.9612 - val_loss: 0.4171 - learning_rate: 7.9634e-08\n",
      "Epoch 85/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9611 - val_loss: 0.4173 - learning_rate: 7.1671e-08\n",
      "Epoch 86/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9611 - val_loss: 0.4172 - learning_rate: 6.4504e-08\n",
      "Epoch 87/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.4549e-04 - val_accuracy: 0.9611 - val_loss: 0.4173 - learning_rate: 5.8053e-08\n",
      "Epoch 88/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9611 - val_loss: 0.4172 - learning_rate: 5.2248e-08\n",
      "Epoch 89/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 8.7186e-04 - val_accuracy: 0.9612 - val_loss: 0.4172 - learning_rate: 4.7023e-08\n",
      "Epoch 90/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9611 - val_loss: 0.4173 - learning_rate: 4.2321e-08\n",
      "Epoch 91/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 9.0044e-04 - val_accuracy: 0.9611 - val_loss: 0.4174 - learning_rate: 3.8089e-08\n",
      "Epoch 92/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9611 - val_loss: 0.4174 - learning_rate: 3.4280e-08\n",
      "Epoch 93/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.5441e-04 - val_accuracy: 0.9611 - val_loss: 0.4175 - learning_rate: 3.0852e-08\n",
      "Epoch 94/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 8.9453e-04 - val_accuracy: 0.9611 - val_loss: 0.4173 - learning_rate: 2.7767e-08\n",
      "Epoch 95/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 6.2820e-04 - val_accuracy: 0.9611 - val_loss: 0.4173 - learning_rate: 2.4990e-08\n",
      "Epoch 96/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.2860e-04 - val_accuracy: 0.9611 - val_loss: 0.4173 - learning_rate: 2.2491e-08\n",
      "Epoch 97/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9611 - val_loss: 0.4173 - learning_rate: 2.0242e-08\n",
      "Epoch 98/100\n",
      "\u001b[1m4090/4090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 5.6499e-04 - val_accuracy: 0.9612 - val_loss: 0.4172 - learning_rate: 1.8218e-08\n",
      "Epoch 99/100\n",
      "Loaded 11271 samples. Labels: [6069 5202]━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 3.8725e-04\n",
      "Input shape: (None, 4, 8, 513)\n",
      "After Dense(num_classes): (None, 2)\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.57      0.89      0.70      6069\n",
      "    Positive       0.64      0.22      0.33      5202\n",
      "\n",
      "    accuracy                           0.58     11271\n",
      "   macro avg       0.60      0.56      0.51     11271\n",
      "weighted avg       0.60      0.58      0.53     11271\n",
      "\n",
      "Classification report saved to 4s_test_classification_inter_report.txt\n"
     ]
    }
   ],
   "source": [
    "def test_model(data_dir, model_path):\n",
    "    X, y = load_data(data_dir)\n",
    "\n",
    "    # 모델 아키텍처를 재구성합니다.\n",
    "    model = build_model(\n",
    "        input_shape=X.shape[1:],  # 데이터 형태에 맞춤\n",
    "        num_classes=2,\n",
    "        embed_dim=64,\n",
    "        num_heads=2,    #2(o) 3(x) 6(o)\n",
    "        ffn_units=128\n",
    "    )\n",
    "\n",
    "    # 저장된 가중치를 불러옵니다.\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    # 입력 데이터의 차원이 모델에 맞는지 확인\n",
    "    input_shape = model.input_shape[1:]\n",
    "    if X.shape[1:] != input_shape:\n",
    "        print(f\"Adjusting test data from {X.shape[1:]} to {input_shape}...\")\n",
    "        X = tf.reshape(X, (-1,) + input_shape)\n",
    "\n",
    "    # 예측 수행\n",
    "    preds = model.predict(X)\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "    # 분류 리포트 생성 및 출력\n",
    "    report = classification_report(y, y_pred, target_names=[\"Negative\", \"Positive\"])\n",
    "    print(\"Test Results:\")\n",
    "    print(report)\n",
    "\n",
    "    # 분류 보고서 저장\n",
    "    report_path = \"4s_test_classification_inter_report.txt\"\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(report)\n",
    "    print(f\"Classification report saved to {report_path}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "data_directory = \"/home/bcml1/2025_EMOTION/DEAP_EEG/overlap4s_seg_conv_ch_BPF+DE/train_overlap0.125\"  # Data path\n",
    "model_save_file = \"4s_0.125overlap_inter_model.h5\"\n",
    "\n",
    "# Train and Evaluate\n",
    "train_and_evaluate_kfold(data_directory, model_save_file, k=5)\n",
    "\n",
    "# Test\n",
    "test_directory = \"/home/bcml1/2025_EMOTION/DEAP_EEG/overlap4s_seg_conv_ch_BPF+DE/test_overlap0.125\"  # Test data path\n",
    "test_model(test_directory, model_save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05987664-4a44-4287-aa7c-566c2b16cfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mycondaenv)",
   "language": "python",
   "name": "mycondaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
